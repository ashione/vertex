# æ·±åº¦ç ”ç©¶å·¥ä½œæµ (Deep Research Workflow)

## æ¦‚è¿°

æ·±åº¦ç ”ç©¶å·¥ä½œæµæ˜¯ä¸€ä¸ªåŸºäºä»£ç æ„å»ºçš„å¤šé˜¶æ®µç ”ç©¶åˆ†æç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºå¯¹å¤æ‚ä¸»é¢˜è¿›è¡Œå…¨é¢ã€æ·±å…¥çš„ç ”ç©¶å’Œåˆ†æã€‚è¯¥å·¥ä½œæµé€šè¿‡å…­ä¸ªè¿ç»­çš„åˆ†æé˜¶æ®µï¼Œä»ä¸»é¢˜åˆ†æåˆ°æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆï¼Œæä¾›ç³»ç»Ÿæ€§çš„ç ”ç©¶æ–¹æ³•å’Œé«˜è´¨é‡çš„åˆ†æç»“æœã€‚

## å·¥ä½œæµæ¶æ„

### ğŸ”„ å…­ä¸ªæ ¸å¿ƒé˜¶æ®µ

1. **ä¸»é¢˜åˆ†æ (Topic Analysis)**
   - åˆ†æç ”ç©¶ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹
   - ç¡®å®šç ”ç©¶èŒƒå›´å’Œè¾¹ç•Œ
   - è¯†åˆ«å…³é”®é—®é¢˜å’Œç ”ç©¶ç»´åº¦
   - é¢„æµ‹ç ”ç©¶è¿‡ç¨‹ä¸­çš„æŒ‘æˆ˜

2. **ç ”ç©¶è§„åˆ’ (Research Planning)**
   - åˆ¶å®šè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’
   - é€‰æ‹©åˆé€‚çš„ç ”ç©¶æ–¹æ³•å’Œå·¥å…·
   - ç¡®å®šä¿¡æ¯æ¥æºå’Œæ•°æ®æ¸ é“
   - è®¾è®¡è´¨é‡æ§åˆ¶æªæ–½

3. **ä¿¡æ¯æ”¶é›† (Information Collection)**
   - ç³»ç»Ÿæ€§æ”¶é›†åŸºç¡€ä¿¡æ¯å’ŒèƒŒæ™¯èµ„æ–™
   - æ¢³ç†å†å²å‘å±•å’Œç°çŠ¶åˆ†æ
   - æ”¶é›†æŠ€æœ¯ç»†èŠ‚å’Œå¸‚åœºæƒ…å†µ
   - æ•´ç†æ¡ˆä¾‹ç ”ç©¶å’Œä¸“å®¶è§‚ç‚¹

4. **æ·±åº¦åˆ†æ (Deep Analysis)**
   - è¿›è¡Œè¶‹åŠ¿åˆ†æå’Œå…³è”åˆ†æ
   - è¯„ä¼°ä¼˜åŠ¿åŠ£åŠ¿å’ŒæŠ€æœ¯æˆç†Ÿåº¦
   - è¯†åˆ«é£é™©å’Œå½±å“å› ç´ 
   - å‘ç°åˆ›æ–°æœºä¼šå’Œæ·±å±‚æ´å¯Ÿ

5. **äº¤å‰éªŒè¯ (Cross Validation)**
   - éªŒè¯å…³é”®äº‹å®å’Œæ•°æ®å‡†ç¡®æ€§
   - æ£€æŸ¥åˆ†æé€»è¾‘çš„åˆç†æ€§
   - è€ƒè™‘åé©³è§‚ç‚¹å’Œæ›¿ä»£è§£é‡Š
   - è¯„ä¼°è¯æ®å¼ºåº¦å’Œä¸ç¡®å®šæ€§

6. **æ€»ç»“æŠ¥å‘Š (Summary Report)**
   - æ•´åˆæ‰€æœ‰ç ”ç©¶æˆæœ
   - æ’°å†™å®Œæ•´çš„ç ”ç©¶æŠ¥å‘Š
   - æä¾›å®è·µå»ºè®®å’Œé£é™©æç¤º
   - é¢„æµ‹æœªæ¥å‘å±•è¶‹åŠ¿

## æ–‡ä»¶ç»“æ„

```
vertex_flow/workflow/app/
â”œâ”€â”€ deep_research_workflow.py    # ä¸»è¦å·¥ä½œæµå®ç°
â”œâ”€â”€ test_deep_research.py        # æµ‹è¯•è„šæœ¬
â””â”€â”€ README_DEEP_RESEARCH.md      # æœ¬æ–‡æ¡£
```

## æ ¸å¿ƒç»„ä»¶

### DeepResearchWorkflow ç±»

ä¸»è¦çš„å·¥ä½œæµæ„å»ºç±»ï¼Œè´Ÿè´£åˆ›å»ºå’Œé…ç½®æ•´ä¸ªç ”ç©¶å·¥ä½œæµã€‚

```python
from vertex_flow.workflow.app.deep_research_workflow import DeepResearchWorkflow

# åˆ›å»ºå·¥ä½œæµå®ä¾‹
workflow_builder = DeepResearchWorkflow(vertex_service)

# æ„å»ºå·¥ä½œæµ
input_data = {
    "content": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
    "env_vars": {},
    "user_vars": {},
    "stream": False
}
workflow = workflow_builder.create_workflow(input_data)
```

### å·¥å‚å‡½æ•°

æä¾›ä¾¿æ·çš„å·¥ä½œæµåˆ›å»ºæ–¹æ³•ï¼š

```python
from vertex_flow.workflow.app.deep_research_workflow import create_deep_research_workflow

# åˆ›å»ºå·¥ä½œæµæ„å»ºå‡½æ•°
builder_func = create_deep_research_workflow(vertex_service)

# ä½¿ç”¨æ„å»ºå‡½æ•°åˆ›å»ºå·¥ä½œæµ
workflow = builder_func(input_data)
```

## ä½¿ç”¨æ–¹æ³•

### 1. é€šè¿‡ API æ¥å£ä½¿ç”¨

å·¥ä½œæµå·²æ³¨å†Œåˆ°ç³»ç»Ÿä¸­ï¼Œå¯ä»¥é€šè¿‡ HTTP API è°ƒç”¨ï¼š

```bash
# POST è¯·æ±‚åˆ°å·¥ä½œæµç«¯ç‚¹
curl -X POST "http://localhost:8000/workflow" \
  -H "Content-Type: application/json" \
  -d '{
    "workflow_name": "deep-research",
    "content": "åŒºå—é“¾æŠ€æœ¯åœ¨é‡‘èç§‘æŠ€ä¸­çš„åº”ç”¨",
    "env_vars": {},
    "user_vars": {},
    "stream": false
  }'
```

### 2. ç›´æ¥åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from vertex_flow.workflow.service import VertexFlowService
from vertex_flow.workflow.app.deep_research_workflow import DeepResearchWorkflow

# åˆå§‹åŒ–æœåŠ¡
vertex_service = VertexFlowService("config/llm.yml")

# åˆ›å»ºå·¥ä½œæµ
workflow_builder = DeepResearchWorkflow(vertex_service)
input_data = {
    "content": "å¯æŒç»­èƒ½æºæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿",
    "stream": False
}

workflow = workflow_builder.create_workflow(input_data)

# æ‰§è¡Œå·¥ä½œæµ
workflow.execute_workflow({}, stream=False)

# è·å–ç»“æœ
results = workflow.result()
print(results['sink']['final_report'])
```

### 3. æµå¼å¤„ç†æ¨¡å¼

æ”¯æŒå®æ—¶æµå¼è¾“å‡ºï¼Œé€‚åˆé•¿æ—¶é—´è¿è¡Œçš„ç ”ç©¶ä»»åŠ¡ï¼š

```python
input_data = {
    "content": "é‡å­è®¡ç®—æŠ€æœ¯çš„å‘å±•ç°çŠ¶",
    "stream": True  # å¯ç”¨æµå¼æ¨¡å¼
}

workflow = workflow_builder.create_workflow(input_data)
workflow.execute_workflow({}, stream=True)

# å¼‚æ­¥è·å–æµå¼ç»“æœ
async for result in workflow.astream("messages"):
    print(f"å®æ—¶ç»“æœ: {result['message']}")
```

## é…ç½®è¯´æ˜

### è¾“å…¥å‚æ•°

- **content**: ç ”ç©¶ä¸»é¢˜ï¼ˆå¿…éœ€ï¼‰
- **env_vars**: ç¯å¢ƒå˜é‡å­—å…¸ï¼ˆå¯é€‰ï¼‰
- **user_vars**: ç”¨æˆ·å˜é‡å­—å…¸ï¼ˆå¯é€‰ï¼‰
- **stream**: æ˜¯å¦å¯ç”¨æµå¼æ¨¡å¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ Falseï¼‰

### è¾“å‡ºç»“æœ

å·¥ä½œæµçš„æœ€ç»ˆè¾“å‡ºåŒ…å«ï¼š

- **final_report**: å®Œæ•´çš„ç ”ç©¶æŠ¥å‘Š
- **message**: æ‰§è¡ŒçŠ¶æ€ä¿¡æ¯
- **research_topic**: åŸå§‹ç ”ç©¶ä¸»é¢˜

## æµ‹è¯•

### è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python vertex_flow/workflow/app/test_deep_research.py

# è¿è¡Œç‰¹å®šæµ‹è¯•
python vertex_flow/workflow/app/test_deep_research.py --test creation
python vertex_flow/workflow/app/test_deep_research.py --test prompts
python vertex_flow/workflow/app/test_deep_research.py --test factory

# æŒ‡å®šé…ç½®æ–‡ä»¶
python vertex_flow/workflow/app/test_deep_research.py --config config/llm.yml
```

### æµ‹è¯•è¦†ç›–èŒƒå›´

- âœ… å·¥ä½œæµåˆ›å»ºæµ‹è¯•
- âœ… æç¤ºè¯æ¨¡æ¿æµ‹è¯•
- âœ… å·¥å‚å‡½æ•°æµ‹è¯•
- âš ï¸ å·¥ä½œæµæ‰§è¡Œæµ‹è¯•ï¼ˆéœ€è¦ API è°ƒç”¨ï¼‰

## æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶è¡Œå¤„ç†

è™½ç„¶å½“å‰å®ç°æ˜¯é¡ºåºæ‰§è¡Œï¼Œä½†å¯ä»¥é€šè¿‡ä¿®æ”¹å·¥ä½œæµç»“æ„å®ç°éƒ¨åˆ†å¹¶è¡Œå¤„ç†ï¼š

```python
# ç¤ºä¾‹ï¼šå¹¶è¡Œæ‰§è¡Œä¿¡æ¯æ”¶é›†çš„ä¸åŒæ–¹é¢
info_collection_tech = LLMVertex(id="info_tech", ...)
info_collection_market = LLMVertex(id="info_market", ...)
info_collection_social = LLMVertex(id="info_social", ...)

# å¹¶è¡Œè¿æ¥
research_planning | info_collection_tech
research_planning | info_collection_market
research_planning | info_collection_social

# æ±‡èšåˆ°æ·±åº¦åˆ†æ
info_collection_tech | deep_analysis
info_collection_market | deep_analysis
info_collection_social | deep_analysis
```

### 2. ç¼“å­˜æœºåˆ¶

å¯¹äºç›¸ä¼¼çš„ç ”ç©¶ä¸»é¢˜ï¼Œå¯ä»¥å®ç°ç»“æœç¼“å­˜ï¼š

```python
import hashlib
import json

def get_cache_key(research_topic: str) -> str:
    """ç”Ÿæˆç ”ç©¶ä¸»é¢˜çš„ç¼“å­˜é”®"""
    return hashlib.md5(research_topic.encode()).hexdigest()

def cache_result(cache_key: str, result: dict):
    """ç¼“å­˜ç ”ç©¶ç»“æœ"""
    # å®ç°ç¼“å­˜é€»è¾‘
    pass
```

### 3. æ¨¡å‹é€‰æ‹©

æ ¹æ®ä¸åŒé˜¶æ®µçš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š

```python
# åˆ†æé˜¶æ®µä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹
deep_analysis = LLMVertex(
    id="deep_analysis",
    params={
        "model": "gpt-4",  # ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹
        "temperature": 0.8,  # æé«˜åˆ›é€ æ€§
        ...
    }
)

# éªŒè¯é˜¶æ®µä½¿ç”¨æ›´ä¿å®ˆçš„è®¾ç½®
cross_validation = LLMVertex(
    id="cross_validation",
    params={
        "model": "gpt-3.5-turbo",  # ä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹
        "temperature": 0.4,  # é™ä½éšæœºæ€§
        ...
    }
)
```

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„åˆ†æé˜¶æ®µ

```python
# æ·»åŠ ç«äº‰åˆ†æé˜¶æ®µ
competitive_analysis = LLMVertex(
    id="competitive_analysis",
    params={
        "model": self.vertex_service.get_chatmodel(),
        "system": self._get_competitive_analysis_system_prompt(),
        "user": [self._get_competitive_analysis_user_prompt()],
        ENABLE_STREAM: stream_mode,
    }
)

# æ’å…¥åˆ°å·¥ä½œæµä¸­
information_collection | competitive_analysis
competitive_analysis | deep_analysis
```

### è‡ªå®šä¹‰æç¤ºè¯

```python
class CustomDeepResearchWorkflow(DeepResearchWorkflow):
    def _get_topic_analysis_system_prompt(self) -> str:
        """è‡ªå®šä¹‰ä¸»é¢˜åˆ†ææç¤ºè¯"""
        return """
        ä½ æ˜¯ä¸€ä½ä¸“é—¨ç ”ç©¶ [ç‰¹å®šé¢†åŸŸ] çš„ä¸“å®¶...
        """
```

### é›†æˆå¤–éƒ¨å·¥å…·

```python
from vertex_flow.workflow.tools.functions import FunctionTool

def web_search_tool(inputs, context=None):
    """ç½‘ç»œæœç´¢å·¥å…·"""
    query = inputs.get("query", "")
    # å®ç°ç½‘ç»œæœç´¢é€»è¾‘
    return {"search_results": "..."}

# æ·»åŠ åˆ° LLM é¡¶ç‚¹
llm_with_tools = LLMVertex(
    id="enhanced_analysis",
    params={...},
    tools=[
        FunctionTool(
            name="web_search",
            description="æœç´¢æœ€æ–°ä¿¡æ¯",
            func=web_search_tool,
            schema={...}
        )
    ]
)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å·¥ä½œæµåˆ›å»ºå¤±è´¥**
   - æ£€æŸ¥ vertex_service æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
   - ç¡®è®¤é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®
   - éªŒè¯æ¨¡å‹é…ç½®æ˜¯å¦æœ‰æ•ˆ

2. **æ‰§è¡Œè¶…æ—¶**
   - è°ƒæ•´æ¨¡å‹çš„ temperature å‚æ•°
   - ç®€åŒ–æç¤ºè¯å†…å®¹
   - è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹

3. **ç»“æœè´¨é‡ä¸ä½³**
   - ä¼˜åŒ–æç¤ºè¯æ¨¡æ¿
   - è°ƒæ•´æ¨¡å‹å‚æ•°
   - å¢åŠ æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æŸ¥çœ‹å·¥ä½œæµçŠ¶æ€
workflow.show_graph(include_dependencies=True)
print(workflow.status())

# æ£€æŸ¥ä¸­é—´ç»“æœ
for vertex_id, result in workflow.result().items():
    print(f"{vertex_id}: {result[:100]}...")
```

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æ·»åŠ æµ‹è¯•ç”¨ä¾‹
4. æäº¤ Pull Request

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªé¡¹ç›®ä¸»ä»“åº“çš„è®¸å¯è¯ã€‚

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤ Issue
- å‘é€é‚®ä»¶
- å‚ä¸è®¨è®º

---

**æ³¨æ„**: æœ¬å·¥ä½œæµéœ€è¦é…ç½®æœ‰æ•ˆçš„ LLM API æ‰èƒ½æ­£å¸¸è¿è¡Œã€‚è¯·ç¡®ä¿åœ¨ `config/llm.yml` ä¸­æ­£ç¡®é…ç½®äº†æ¨¡å‹æœåŠ¡ã€‚