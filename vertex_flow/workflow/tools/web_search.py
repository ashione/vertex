import json
import logging
import re
import time
from typing import Any, Dict, List, Optional
from urllib.parse import quote_plus

import requests

from vertex_flow.utils.logger import LoggerUtil
from vertex_flow.workflow.tools.functions import FunctionTool

logging = LoggerUtil.get_logger()


def _is_valid_date_format(freshness: str) -> bool:
    """éªŒè¯æ—¥æœŸæ ¼å¼æ˜¯å¦æœ‰æ•ˆ

    Args:
        freshness: æ—¥æœŸå­—ç¬¦ä¸²

    Returns:
        bool: æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ—¥æœŸæ ¼å¼
    """
    # åŒ¹é… YYYY-MM-DD æ ¼å¼
    single_date_pattern = r"^\d{4}-\d{2}-\d{2}$"
    # åŒ¹é… YYYY-MM-DD..YYYY-MM-DD æ ¼å¼
    date_range_pattern = r"^\d{4}-\d{2}-\d{2}\.\.\d{4}-\d{2}-\d{2}$"

    return bool(re.match(single_date_pattern, freshness) or re.match(date_range_pattern, freshness))


class BochaWebSearch:
    """åšæŸ¥Webæœç´¢APIå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str):
        """åˆå§‹åŒ–åšæŸ¥æœç´¢å®¢æˆ·ç«¯

        Args:
            api_key: åšæŸ¥APIå¯†é’¥
        """
        self.api_key = api_key
        self.base_url = "https://api.bochaai.com/v1"
        self.headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    def search(
        self, query: str, count: int = 8, freshness: str = "noLimit", summary: bool = True, search_type: str = "web"
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒWebæœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
            count: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤8ä¸ª
            freshness: æœç´¢ç»“æœæ—¶æ•ˆæ€§ï¼Œå¯é€‰å€¼:
                - noLimit: ä¸é™ï¼ˆé»˜è®¤ï¼Œæ¨èä½¿ç”¨ï¼‰
                - oneDay: ä¸€å¤©å†…
                - oneWeek: ä¸€å‘¨å†…
                - oneMonth: ä¸€ä¸ªæœˆå†…
                - oneYear: ä¸€å¹´å†…
                - YYYY-MM-DD..YYYY-MM-DD: æœç´¢æ—¥æœŸèŒƒå›´
                - YYYY-MM-DD: æœç´¢æŒ‡å®šæ—¥æœŸ
            summary: æ˜¯å¦è¿”å›AIæ€»ç»“ï¼Œé»˜è®¤True
            search_type: æœç´¢ç±»å‹ï¼Œé»˜è®¤"web"

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        url = f"{self.base_url}/web-search"

        payload = {"query": query, "count": count, "freshness": freshness, "summary": summary}

        try:
            response = requests.post(url, headers=self.headers, json=payload, timeout=30)
            response.raise_for_status()

            result = response.json()
            # åšæŸ¥APIå“åº”æ ¼å¼: result.data.webPages
            data = result.get("data", {})
            logging.info(f"åšæŸ¥æœç´¢æˆåŠŸï¼ŒæŸ¥è¯¢: {query}, è¿”å›ç»“æœæ•°: {len(data.get('webPages', {}).get('value', []))}")
            return data

        except requests.exceptions.RequestException as e:
            logging.error(f"åšæŸ¥æœç´¢è¯·æ±‚å¤±è´¥: {e}, {response}")
            return {"error": f"æœç´¢è¯·æ±‚å¤±è´¥: {str(e)}", "webPages": {"value": []}}
        except json.JSONDecodeError as e:
            logging.error(f"åšæŸ¥æœç´¢å“åº”è§£æå¤±è´¥: {e}")
            return {"error": f"å“åº”è§£æå¤±è´¥: {str(e)}", "webPages": {"value": []}}


def web_search_function(inputs: Dict[str, Any], context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """ç»Ÿä¸€çš„Webæœç´¢å·¥å…·å‡½æ•°

    è¿™æ˜¯ä¸€ä¸ªå¯ç”¨äºfunction callingçš„Webæœç´¢å·¥å…·ï¼Œæ”¯æŒå¤šç§æœç´¢æœåŠ¡ã€‚
    æ ¹æ®é…ç½®æ–‡ä»¶è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„æœç´¢æœåŠ¡ï¼Œæ”¯æŒBocha AIã€DuckDuckGoã€SerpAPIç­‰ã€‚

    Args:
        inputs: è¾“å…¥å‚æ•°å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
            - query (str): å¿…éœ€ï¼Œæœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
            - count (int): å¯é€‰ï¼Œè¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5
            - freshness (str): å¯é€‰ï¼Œæœç´¢ç»“æœæ—¶æ•ˆæ€§ï¼Œé»˜è®¤"noLimit"ï¼Œå¯é€‰å€¼:
                * noLimit: ä¸é™ï¼ˆé»˜è®¤ï¼Œæ¨èä½¿ç”¨ï¼‰
                * oneDay: ä¸€å¤©å†…
                * oneWeek: ä¸€å‘¨å†…
                * oneMonth: ä¸€ä¸ªæœˆå†…
                * oneYear: ä¸€å¹´å†…
                * YYYY-MM-DD..YYYY-MM-DD: æœç´¢æ—¥æœŸèŒƒå›´ï¼ˆä»…Bochaæ”¯æŒï¼‰
                * YYYY-MM-DD: æœç´¢æŒ‡å®šæ—¥æœŸï¼ˆä»…Bochaæ”¯æŒï¼‰
            - summary (bool): å¯é€‰ï¼Œæ˜¯å¦è¿”å›AIæ€»ç»“ï¼Œé»˜è®¤Trueï¼ˆä»…Bochaæ”¯æŒï¼‰
        context: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆå¯é€‰ï¼‰

    Returns:
        æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
            - success (bool): æœç´¢æ˜¯å¦æˆåŠŸ
            - query (str): åŸå§‹æŸ¥è¯¢å­—ç¬¦ä¸²
            - summary (str): AIç”Ÿæˆçš„æœç´¢ç»“æœæ€»ç»“ï¼ˆå¦‚æœæ”¯æŒä¸”å¯ç”¨ï¼‰
            - results (List[Dict]): æœç´¢ç»“æœåˆ—è¡¨
            - total_count (int): æ€»ç»“æœæ•°é‡
            - search_engine (str): å®é™…ä½¿ç”¨çš„æœç´¢å¼•æ“
            - error (str): é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰

    Example:
        >>> inputs = {
        ...     "query": "äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•è¶‹åŠ¿",
        ...     "count": 5,
        ...     "summary": True
        ... }
        >>> result = web_search_function(inputs)
        >>> print(f"ä½¿ç”¨æœç´¢å¼•æ“: {result['search_engine']}")
        >>> if result['summary']:
        ...     print(f"AIæ€»ç»“: {result['summary']}")
        >>> for item in result['results']:
        ...     print(f"{item['title']}: {item['url']}")
    """
    # å‚æ•°éªŒè¯
    if not inputs.get("query"):
        return {"success": False, "error": "æŸ¥è¯¢å‚æ•°ä¸èƒ½ä¸ºç©º", "search_engine": "none"}

    query = inputs.get("query", "")
    count = inputs.get("count", 5)
    freshness = inputs.get("freshness", "noLimit")
    summary = inputs.get("summary", True)

    # å‚æ•°ç±»å‹éªŒè¯
    if not query or not isinstance(query, str):
        return {"success": False, "error": "æŸ¥è¯¢å‚æ•°å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²", "search_engine": "none"}
    if not isinstance(count, int) or count <= 0:
        count = 5

    # è·å–æœç´¢æœåŠ¡é…ç½®
    try:
        from vertex_flow.workflow.service import VertexFlowService

        service = VertexFlowService.get_instance()

        # å°è¯•ä¸åŒçš„æœç´¢æœåŠ¡ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        search_services = [
            ("bocha", _search_with_bocha),
            ("duckduckgo", _search_with_duckduckgo),
            ("serpapi", _search_with_serpapi),
            ("searchapi", _search_with_searchapi),
        ]

        for service_name, search_func in search_services:
            logging.info(f"å°è¯•æœç´¢å¼•æ“: {service_name}")
            try:
                result = search_func(service, query, count, freshness, summary)
                if result["success"]:
                    result["search_engine"] = service_name
                    logging.info(f"Webæœç´¢æˆåŠŸï¼Œä½¿ç”¨å¼•æ“: {service_name}, æŸ¥è¯¢: {query}")
                    return result
                else:
                    logging.warning(f"æœç´¢å¼•æ“ {service_name} å¤±è´¥: {result.get('error', 'Unknown error')}")
            except Exception as e:
                logging.error(f"æœç´¢å¼•æ“ {service_name} å¼‚å¸¸: {e}")
                continue

        # æ‰€æœ‰æœç´¢æœåŠ¡éƒ½å¤±è´¥
        return {
            "success": False,
            "error": "æ‰€æœ‰æœç´¢æœåŠ¡éƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®æˆ–ç½‘ç»œè¿æ¥",
            "query": query,
            "summary": "",
            "results": [],
            "total_count": 0,
            "search_engine": "none",
        }

    except Exception as e:
        logging.error(f"Webæœç´¢é…ç½®è·å–å¤±è´¥: {e}")
        return {
            "success": False,
            "error": f"æœç´¢é…ç½®è·å–å¤±è´¥: {str(e)}",
            "query": query,
            "summary": "",
            "results": [],
            "total_count": 0,
            "search_engine": "none",
        }


def _search_with_bocha(service, query: str, count: int, freshness: str, summary: bool) -> Dict[str, Any]:
    """ä½¿ç”¨Bocha AIæœç´¢"""
    try:
        config = service.get_web_search_config("bocha")
        if not config.get("enabled", False):
            return {"success": False, "error": "Bochaæœç´¢æœåŠ¡æœªå¯ç”¨"}

        if not config.get("api_key"):
            return {"success": False, "error": "Bochaæœç´¢APIå¯†é’¥æœªé…ç½®"}

        # freshnesså‚æ•°éªŒè¯ï¼šæ”¯æŒé¢„å®šä¹‰å€¼å’Œæ—¥æœŸæ ¼å¼
        valid_freshness = ["noLimit", "oneDay", "oneWeek", "oneMonth", "oneYear"]
        if not isinstance(freshness, str) or (
            freshness not in valid_freshness and not _is_valid_date_format(freshness)
        ):
            freshness = "noLimit"
        if not isinstance(summary, bool):
            summary = True

        # æ‰§è¡ŒBochaæœç´¢
        search_client = BochaWebSearch(config["api_key"])
        search_result = search_client.search(query=query, count=count, freshness=freshness, summary=summary)

        if "error" in search_result:
            return {"success": False, "error": search_result["error"]}

        # æå–ç»“æœ
        web_pages = search_result.get("webPages", {})
        results = web_pages.get("value", [])
        total_count = web_pages.get("totalEstimatedMatches", len(results))

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for item in results:
            formatted_results.append(
                {
                    "title": item.get("name", ""),
                    "url": item.get("url", ""),
                    "snippet": item.get("snippet", ""),
                    "site_name": item.get("siteName", ""),
                    "source": "Bocha AI",
                }
            )

        # æå–AIæ€»ç»“
        ai_summary = search_result.get("summary", {}).get("content", "") if summary else ""

        return {
            "success": True,
            "query": query,
            "summary": ai_summary,
            "results": formatted_results,
            "total_count": total_count,
            "error": "",
        }

    except Exception as e:
        return {"success": False, "error": f"Bochaæœç´¢å¤±è´¥: {str(e)}"}


def _direct_serpapi_search(api_key: str, query: str, count: int = 5) -> Dict[str, Any]:
    """ç›´æ¥è°ƒç”¨SerpAPIè¿›è¡Œæœç´¢"""
    try:
        url = "https://serpapi.com/search"
        params = {
            "engine": "google",  # ä½¿ç”¨Googleå¼•æ“è·å¾—æ›´å¥½çš„æœç´¢ç»“æœ
            "q": query,
            "api_key": api_key,
            "num": min(count, 10),  # SerpAPIé™åˆ¶æ¯æ¬¡æœ€å¤š10ä¸ªç»“æœ
        }

        response = requests.get(url, params=params, timeout=15)
        response.raise_for_status()

        data = response.json()

        results = []
        # æ£€æŸ¥æœ‰æœºæœç´¢ç»“æœ
        if data.get("organic_results"):
            for result in data["organic_results"][:count]:
                results.append(
                    {
                        "title": result.get("title", ""),
                        "url": result.get("link", ""),
                        "snippet": result.get("snippet", ""),
                        "source": "SerpAPI-Google",
                    }
                )

        # æ£€æŸ¥çŸ¥è¯†é¢æ¿
        elif data.get("knowledge_graph"):
            kg = data["knowledge_graph"]
            results.append(
                {
                    "title": kg.get("title", ""),
                    "url": kg.get("website", ""),
                    "snippet": kg.get("description", ""),
                    "source": "SerpAPI-Knowledge Graph",
                }
            )

        return {"results": results, "total_count": len(results)}

    except Exception as e:
        logging.error(f"SerpAPIç›´æ¥æœç´¢å¤±è´¥: {e}")
        return {"error": str(e)}


def _search_with_duckduckgo(service, query: str, count: int, freshness: str, summary: bool) -> Dict[str, Any]:
    """ä½¿ç”¨DuckDuckGoæœç´¢"""
    logging.info(f"DuckDuckGoæœç´¢: {query}, {count}, {freshness}, {summary}")

    try:
        config = service.get_web_search_config("duckduckgo")
        if not config.get("enabled", False):
            return {"success": False, "error": "DuckDuckGoæœç´¢æœåŠ¡æœªå¯ç”¨"}

        # ä½¿ç”¨WebSearchToolçš„å…è´¹æœç´¢åŠŸèƒ½
        web_tool = WebSearchTool(config)
        search_result = web_tool.free_search.search_duckduckgo_instant(query)

        if "error" in search_result:
            return {"success": False, "error": search_result["error"]}

        results = search_result.get("results", [])
        instant_answer = search_result.get("instant_answer")

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for item in results[:count]:
            formatted_results.append(
                {
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "snippet": item.get("snippet", ""),
                    "site_name": "",
                    "source": "DuckDuckGo",
                }
            )

        # å¦‚æœæœ‰å³æ—¶ç­”æ¡ˆä½†æ²¡æœ‰æœç´¢ç»“æœï¼Œå°†å³æ—¶ç­”æ¡ˆä½œä¸ºä¸€ä¸ªç»“æœ
        if instant_answer and not formatted_results:
            formatted_results.append(
                {
                    "title": f"å³æ—¶ç­”æ¡ˆ: {query}",
                    "url": f"https://duckduckgo.com/?q={query.replace(' ', '+')}",
                    "snippet": instant_answer.get("answer", ""),
                    "site_name": instant_answer.get("source", "DuckDuckGo"),
                    "source": "DuckDuckGo Instant Answer",
                }
            )

        # å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœï¼Œåˆ›å»ºä¸€ä¸ªæœç´¢é“¾æ¥ä½œä¸ºå¤‡ç”¨
        if not formatted_results:
            formatted_results.append(
                {
                    "title": f"åœ¨DuckDuckGoä¸Šæœç´¢: {query}",
                    "url": f"https://duckduckgo.com/?q={query.replace(' ', '+')}",
                    "snippet": f"ç‚¹å‡»æŸ¥çœ‹å…³äº'{query}'çš„å®Œæ•´æœç´¢ç»“æœ",
                    "site_name": "DuckDuckGo",
                    "source": "DuckDuckGo Search",
                }
            )

        # å¦‚æœæœ‰å³æ—¶ç­”æ¡ˆï¼Œæ·»åŠ åˆ°æ€»ç»“ä¸­
        ai_summary = ""
        if instant_answer and summary:
            ai_summary = f"å³æ—¶ç­”æ¡ˆ: {instant_answer.get('answer', '')}"
            if instant_answer.get("source"):
                ai_summary += f" (æ¥æº: {instant_answer['source']})"
        elif summary:
            ai_summary = f"ä¸ºæ‚¨æ‰¾åˆ°å…³äº'{query}'çš„æœç´¢ç»“æœ"

        logging.info(f"DuckDuckGoæœç´¢ç»“æœ: {formatted_results}, {ai_summary}")

        return {
            "success": True,
            "query": query,
            "summary": ai_summary,
            "results": formatted_results,
            "total_count": len(formatted_results),
            "error": "",
        }

    except Exception as e:
        return {"success": False, "error": f"DuckDuckGoæœç´¢å¤±è´¥: {str(e)}"}


def _search_with_serpapi(service, query: str, count: int, freshness: str, summary: bool) -> Dict[str, Any]:
    """ä½¿ç”¨SerpAPIæœç´¢"""
    try:
        config = service.get_web_search_config("serpapi")
        if not config.get("enabled", False):
            return {"success": False, "error": "SerpAPIæœç´¢æœåŠ¡æœªå¯ç”¨"}

        if not config.get("api_key"):
            return {"success": False, "error": "SerpAPIå¯†é’¥æœªé…ç½®"}

        # ç›´æ¥è°ƒç”¨SerpAPIï¼Œä¸ä½¿ç”¨FreeWebSearchTool
        search_result = _direct_serpapi_search(config.get("api_key"), query, count)

        if "error" in search_result:
            return {"success": False, "error": search_result["error"]}

        results = search_result.get("results", [])
        if not results:
            return {"success": False, "error": "SerpAPIæœç´¢æ— ç»“æœ"}

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for item in results[:count]:
            formatted_results.append(
                {
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "snippet": item.get("snippet", ""),
                    "site_name": "",
                    "source": "SerpAPI",
                }
            )

        # ç”Ÿæˆç®€å•æ€»ç»“
        ai_summary = ""
        if summary and formatted_results:
            ai_summary = f"é€šè¿‡SerpAPIæ‰¾åˆ° {len(formatted_results)} ä¸ªç›¸å…³ç»“æœ"

        return {
            "success": True,
            "query": query,
            "summary": ai_summary,
            "results": formatted_results,
            "total_count": len(formatted_results),
            "error": "",
        }

    except Exception as e:
        return {"success": False, "error": f"SerpAPIæœç´¢å¤±è´¥: {str(e)}"}


def _search_with_searchapi(service, query: str, count: int, freshness: str, summary: bool) -> Dict[str, Any]:
    """ä½¿ç”¨SearchAPIæœç´¢"""
    try:
        config = service.get_web_search_config("searchapi")
        if not config.get("enabled", False):
            return {"success": False, "error": "SearchAPIæœç´¢æœåŠ¡æœªå¯ç”¨"}

        if not config.get("api_key"):
            return {"success": False, "error": "SearchAPIå¯†é’¥æœªé…ç½®"}

        # ä½¿ç”¨FreeWebSearchToolçš„SearchAPIåŠŸèƒ½
        free_search = FreeWebSearchTool(config)
        search_result = free_search.search_searchapi_free(query)

        if "error" in search_result:
            return {"success": False, "error": search_result["error"]}

        results = search_result.get("results", [])
        if not results:
            return {"success": False, "error": "SearchAPIæœç´¢æ— ç»“æœ"}

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for item in results[:count]:
            formatted_results.append(
                {
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "snippet": item.get("snippet", ""),
                    "site_name": "",
                    "source": "SearchAPI",
                }
            )

        # ç”Ÿæˆç®€å•æ€»ç»“
        ai_summary = ""
        if summary and formatted_results:
            ai_summary = f"é€šè¿‡SearchAPIæ‰¾åˆ° {len(formatted_results)} ä¸ªç›¸å…³ç»“æœ"

        return {
            "success": True,
            "query": query,
            "summary": ai_summary,
            "results": formatted_results,
            "total_count": len(formatted_results),
            "error": "",
        }

    except Exception as e:
        return {"success": False, "error": f"SearchAPIæœç´¢å¤±è´¥: {str(e)}"}


def create_web_search_tool() -> FunctionTool:
    """åˆ›å»ºç»Ÿä¸€çš„Webæœç´¢å·¥å…·å®ä¾‹

    Returns:
        é…ç½®å¥½çš„FunctionToolå®ä¾‹ï¼Œæ”¯æŒå¤šç§æœç´¢å¼•æ“ï¼Œå¯ç›´æ¥ç”¨äºfunction calling
    """
    schema = {
        "type": "object",
        "properties": {
            "query": {"type": "string", "description": "æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œæè¿°è¦æœç´¢çš„å†…å®¹"},
            "count": {
                "type": "integer",
                "description": "è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5ä¸ªï¼ŒèŒƒå›´1-20",
                "minimum": 1,
                "maximum": 20,
                "default": 5,
            },
            "freshness": {
                "type": "string",
                "description": "æœç´¢ç»“æœæ—¶æ•ˆæ€§ã€‚å¯é€‰å€¼ï¼šnoLimitï¼ˆä¸é™ï¼Œé»˜è®¤æ¨èï¼‰ã€oneDayï¼ˆä¸€å¤©å†…ï¼‰ã€oneWeekï¼ˆä¸€å‘¨å†…ï¼‰ã€oneMonthï¼ˆä¸€ä¸ªæœˆå†…ï¼‰ã€oneYearï¼ˆä¸€å¹´å†…ï¼‰ã€‚æ³¨æ„ï¼šæ—¥æœŸèŒƒå›´æ ¼å¼ï¼ˆYYYY-MM-DD..YYYY-MM-DDï¼‰å’ŒæŒ‡å®šæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ä»…Bocha AIæ”¯æŒ",
                "default": "noLimit",
            },
            "summary": {
                "type": "boolean",
                "description": "æ˜¯å¦è¿”å›AIç”Ÿæˆçš„æœç´¢ç»“æœæ€»ç»“ã€‚æ³¨æ„ï¼šAIæ€»ç»“åŠŸèƒ½ä¸»è¦ç”±Bocha AIæ”¯æŒï¼Œå…¶ä»–å¼•æ“æä¾›ç®€å•æ€»ç»“",
                "default": True,
            },
        },
        "required": ["query"],
    }

    return FunctionTool(
        name="web_search",
        description="æ™ºèƒ½Webæœç´¢å·¥å…·ï¼Œæ”¯æŒå¤šç§æœç´¢å¼•æ“ã€‚æ ¹æ®é…ç½®æŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„æœç´¢æœåŠ¡ï¼šBocha AIï¼ˆé«˜è´¨é‡AIæ€»ç»“ï¼‰ã€DuckDuckGoï¼ˆå…è´¹å³æ—¶ç­”æ¡ˆï¼‰ã€SerpAPIï¼ˆGoogleæœç´¢ç»“æœï¼‰ã€SearchAPIï¼ˆå¤šæœç´¢å¼•æ“æ”¯æŒï¼‰ã€‚æ¯æ¬¡åªä½¿ç”¨ä¸€ä¸ªå¯ç”¨çš„æœç´¢æœåŠ¡ã€‚å¯ä»¥æœç´¢æœ€æ–°çš„ç½‘ç»œä¿¡æ¯ï¼Œæ”¯æŒæ–°é—»ã€ç™¾ç§‘ã€å­¦æœ¯ç­‰å¤šç§å†…å®¹æºã€‚é€‚ç”¨äºè·å–å®æ—¶ä¿¡æ¯ã€ç ”ç©¶èµ„æ–™æ”¶é›†ã€äº‹å®æ ¸æŸ¥ç­‰åœºæ™¯ã€‚",
        func=web_search_function,
        schema=schema,
        id="web_search_unified",
    )


# ä¾¿æ·çš„å·¥å…·å®ä¾‹
web_search_tool = create_web_search_tool()


class FreeWebSearchTool:
    """
    Free Web Search Tool - é›†æˆå¤šä¸ªå…è´¹APIçš„æœç´¢å·¥å…·

    æ”¯æŒçš„å…è´¹API:
    1. DuckDuckGo Instant Answer API (å®Œå…¨å…è´¹)
    2. SerpAPIå…è´¹å±‚ (æ¯æœˆ100æ¬¡)
    3. SearchAPI.ioå…è´¹å±‚ (æ¯æœˆ100æ¬¡)
    4. å¤‡ç”¨HTMLè§£ææœç´¢
    """

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.logger = LoggerUtil.get_logger(__name__)

        # APIé…ç½®
        self.serpapi_key = self.config.get("serpapi_key")
        self.searchapi_key = self.config.get("searchapi_key")

        # å…è´¹APIé™åˆ¶è·Ÿè¸ª
        self.daily_usage = {"serpapi": 0, "searchapi": 0, "duckduckgo": 0}

    def search_duckduckgo_instant(self, query: str) -> Dict[str, Any]:
        """
        DuckDuckGo Instant Answer API - å®Œå…¨å…è´¹
        ä¸»è¦ç”¨äºè·å–å³æ—¶ç­”æ¡ˆï¼Œä¸æ˜¯å®Œæ•´çš„æœç´¢ç»“æœ
        """
        try:
            url = "https://api.duckduckgo.com/"
            params = {"q": query, "format": "json", "no_html": "1", "skip_disambig": "1"}

            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            results = {"query": query, "source": "duckduckgo_instant", "results": [], "instant_answer": None}

            # å³æ—¶ç­”æ¡ˆ
            if data.get("Answer"):
                results["instant_answer"] = {
                    "answer": data["Answer"],
                    "answer_type": data.get("AnswerType", ""),
                    "source": data.get("AbstractSource", ""),
                }

            # ç›¸å…³ä¸»é¢˜
            if data.get("RelatedTopics"):
                for topic in data["RelatedTopics"][:5]:  # é™åˆ¶5ä¸ªç»“æœ
                    if isinstance(topic, dict) and topic.get("Text"):
                        results["results"].append(
                            {
                                "title": (
                                    topic.get("Text", "")[:100] + "..."
                                    if len(topic.get("Text", "")) > 100
                                    else topic.get("Text", "")
                                ),
                                "url": topic.get("FirstURL", ""),
                                "snippet": topic.get("Text", ""),
                                "source": "DuckDuckGo",
                            }
                        )

            self.daily_usage["duckduckgo"] += 1
            return results

        except Exception as e:
            self.logger.error(f"DuckDuckGoæœç´¢å¤±è´¥: {e}")
            return {"error": str(e), "source": "duckduckgo_instant"}

    def search_serpapi_free(self, query: str) -> Dict[str, Any]:
        """
        SerpAPIå…è´¹å±‚ - æ¯æœˆ100æ¬¡å…è´¹æœç´¢
        """
        if not self.serpapi_key:
            return {"error": "SerpAPI key not configured", "source": "serpapi"}

        if self.daily_usage["serpapi"] >= 3:  # æ¯æ—¥é™åˆ¶3æ¬¡ï¼ŒèŠ‚çœæœˆåº¦é…é¢
            return {"error": "Daily SerpAPI quota exceeded", "source": "serpapi"}

        try:
            url = "https://serpapi.com/search"
            params = {"engine": "duckduckgo", "q": query, "api_key": self.serpapi_key}

            response = requests.get(url, params=params, timeout=15)
            response.raise_for_status()

            data = response.json()

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            results = {"query": query, "source": "serpapi_duckduckgo", "results": []}

            # æœ‰æœºæœç´¢ç»“æœ
            if data.get("organic_results"):
                for result in data["organic_results"][:5]:
                    results["results"].append(
                        {
                            "title": result.get("title", ""),
                            "url": result.get("link", ""),
                            "snippet": result.get("snippet", ""),
                            "source": "SerpAPI-DuckDuckGo",
                        }
                    )

            self.daily_usage["serpapi"] += 1
            return results

        except Exception as e:
            self.logger.error(f"SerpAPIæœç´¢å¤±è´¥: {e}")
            return {"error": str(e), "source": "serpapi"}

    def search_searchapi_free(self, query: str) -> Dict[str, Any]:
        """
        SearchAPI.ioå…è´¹å±‚ - æ¯æœˆ100æ¬¡å…è´¹æœç´¢
        """
        if not self.searchapi_key:
            return {"error": "SearchAPI key not configured", "source": "searchapi"}

        if self.daily_usage["searchapi"] >= 3:  # æ¯æ—¥é™åˆ¶3æ¬¡
            return {"error": "Daily SearchAPI quota exceeded", "source": "searchapi"}

        try:
            url = "https://www.searchapi.io/api/v1/search"
            params = {"engine": "duckduckgo", "q": query, "api_key": self.searchapi_key}

            response = requests.get(url, params=params, timeout=15)
            response.raise_for_status()

            data = response.json()

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            results = {"query": query, "source": "searchapi_duckduckgo", "results": []}

            # æœ‰æœºæœç´¢ç»“æœ
            if data.get("organic_results"):
                for result in data["organic_results"][:5]:
                    results["results"].append(
                        {
                            "title": result.get("title", ""),
                            "url": result.get("link", ""),
                            "snippet": result.get("snippet", ""),
                            "source": "SearchAPI-DuckDuckGo",
                        }
                    )

            self.daily_usage["searchapi"] += 1
            return results

        except Exception as e:
            self.logger.error(f"SearchAPIæœç´¢å¤±è´¥: {e}")
            return {"error": str(e), "source": "searchapi"}

    def search_backup_html(self, query: str) -> Dict[str, Any]:
        """
        å¤‡ç”¨HTMLè§£ææœç´¢ - ç›´æ¥è§£ææœç´¢å¼•æ“ç»“æœé¡µé¢
        ä½œä¸ºæœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
        """
        try:
            # ä½¿ç”¨DuckDuckGoçš„HTMLæœç´¢ï¼ˆæ›´å®½æ¾çš„robots.txtï¼‰
            url = "https://html.duckduckgo.com/html/"
            params = {"q": query}

            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }

            response = requests.get(url, params=params, headers=headers, timeout=10)
            response.raise_for_status()

            # ç®€å•çš„HTMLè§£æï¼ˆè¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
            html = response.text
            results = {"query": query, "source": "backup_html", "results": []}

            # æ·»åŠ ä¸€ä¸ªç®€å•çš„ç»“æœè¯´æ˜
            results["results"].append(
                {
                    "title": f"æœç´¢ç»“æœ: {query}",
                    "url": f"https://duckduckgo.com/?q={quote_plus(query)}",
                    "snippet": f'æ‰¾åˆ°äº†å…³äº"{query}"çš„æœç´¢ç»“æœã€‚ç‚¹å‡»æŸ¥çœ‹å®Œæ•´ç»“æœã€‚',
                    "source": "Backup Search",
                }
            )

            return results

        except Exception as e:
            self.logger.error(f"å¤‡ç”¨æœç´¢å¤±è´¥: {e}")
            return {"error": str(e), "source": "backup_html"}

    def search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """
        æ™ºèƒ½æœç´¢ - æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„API
        """
        self.logger.info(f"å¼€å§‹æœç´¢: {query}")

        # æœç´¢ç­–ç•¥ä¼˜å…ˆçº§
        search_methods = [
            ("DuckDuckGo Instant", self.search_duckduckgo_instant),
            ("SerpAPI Free", self.search_serpapi_free),
            ("SearchAPI Free", self.search_searchapi_free),
            ("Backup HTML", self.search_backup_html),
        ]

        all_results = []
        errors = []

        for method_name, method in search_methods:
            try:
                self.logger.info(f"å°è¯•ä½¿ç”¨ {method_name} æœç´¢")
                result = method(query)

                if "error" not in result and result.get("results"):
                    all_results.extend(result["results"])
                    self.logger.info(f"{method_name} æœç´¢æˆåŠŸï¼Œè·å¾— {len(result['results'])} ä¸ªç»“æœ")

                    # å¦‚æœå·²ç»æœ‰è¶³å¤Ÿçš„ç»“æœï¼Œå°±åœæ­¢
                    if len(all_results) >= max_results:
                        break
                else:
                    if "error" in result:
                        errors.append(f"{method_name}: {result['error']}")
                        self.logger.warning(f"{method_name} æœç´¢å¤±è´¥: {result['error']}")

                # é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                time.sleep(0.5)

            except Exception as e:
                error_msg = f"{method_name}: {str(e)}"
                errors.append(error_msg)
                self.logger.error(f"{method_name} æœç´¢å¼‚å¸¸: {e}")

        # å»é‡å’Œé™åˆ¶ç»“æœæ•°é‡
        unique_results = []
        seen_urls = set()

        for result in all_results:
            url = result.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
                if len(unique_results) >= max_results:
                    break

        # æ„å»ºæœ€ç»ˆç»“æœ
        final_result = {
            "query": query,
            "total_results": len(unique_results),
            "results": unique_results,
            "search_methods_used": [
                method[0] for method in search_methods if method[0] not in [e.split(":")[0] for e in errors]
            ],
            "errors": errors if errors else None,
            "usage_stats": self.daily_usage.copy(),
        }

        self.logger.info(f"æœç´¢å®Œæˆï¼Œæ€»å…±è·å¾— {len(unique_results)} ä¸ªæœ‰æ•ˆç»“æœ")
        return final_result


class WebSearchTool:
    def __init__(self, config=None):
        self.config = config or {}
        self.logger = LoggerUtil.get_logger(__name__)

        # ä¼˜å…ˆä½¿ç”¨å…è´¹æœç´¢å·¥å…·
        self.free_search = FreeWebSearchTool(config)

        # ä¿æŒåŸæœ‰çš„ä»˜è´¹APIé…ç½®ä½œä¸ºå¤‡é€‰
        self.serp_api_key = self.config.get("serp_api_key")
        self.google_api_key = self.config.get("google_api_key")
        self.google_cse_id = self.config.get("google_cse_id")

    def search_web(self, query: str, num_results: int = 5) -> str:
        """
        Webæœç´¢ä¸»å…¥å£ - ä¼˜å…ˆä½¿ç”¨å…è´¹API
        """
        try:
            # é¦–å…ˆå°è¯•å…è´¹æœç´¢
            result = self.free_search.search(query, num_results)

            logging.info(f"æœç´¢ç»“æœ: {result}")

            if result.get("results"):
                # æ ¼å¼åŒ–ç»“æœ
                formatted_results = []
                for i, item in enumerate(result["results"], 1):
                    formatted_result = f"{i}. **{item.get('title', 'No Title')}**\n"
                    formatted_result += f"   URL: {item.get('url', 'No URL')}\n"
                    formatted_result += f"   æ‘˜è¦: {item.get('snippet', 'No snippet available')}\n"
                    formatted_result += f"   æ¥æº: {item.get('source', 'Unknown')}\n"
                    formatted_results.append(formatted_result)

                search_summary = f"ğŸ” æœç´¢æŸ¥è¯¢: {query}\n"
                search_summary += f"ğŸ“Š æ‰¾åˆ° {result['total_results']} ä¸ªç»“æœ\n"
                search_summary += f"ğŸ› ï¸ ä½¿ç”¨çš„æœç´¢æ–¹æ³•: {', '.join(result.get('search_methods_used', []))}\n\n"

                if result.get("errors"):
                    search_summary += f"âš ï¸ éƒ¨åˆ†æœç´¢æ–¹æ³•å¤±è´¥: {'; '.join(result['errors'])}\n\n"

                search_summary += "ğŸ“‹ æœç´¢ç»“æœ:\n" + "\n".join(formatted_results)

                # æ·»åŠ ä½¿ç”¨ç»Ÿè®¡
                usage_stats = result.get("usage_stats", {})
                if any(usage_stats.values()):
                    search_summary += f"\nğŸ“ˆ ä»Šæ—¥APIä½¿ç”¨æƒ…å†µ: "
                    stats = [f"{k}: {v}" for k, v in usage_stats.items() if v > 0]
                    search_summary += ", ".join(stats)

                return search_summary
            else:
                # å¦‚æœå…è´¹æœç´¢å¤±è´¥ï¼Œå°è¯•åŸæœ‰çš„ä»˜è´¹API
                return self._fallback_search(query, num_results)

        except Exception as e:
            self.logger.error(f"æœç´¢å¤±è´¥: {e}")
            return f"æœç´¢å¤±è´¥: {str(e)}"

    def _fallback_search(self, query: str, num_results: int = 5) -> str:
        """
        å¤‡ç”¨æœç´¢æ–¹æ³• - ä½¿ç”¨åŸæœ‰çš„ä»˜è´¹APIé€»è¾‘
        """
        return f"å…è´¹æœç´¢APIæš‚æ—¶ä¸å¯ç”¨ï¼Œå»ºè®®é…ç½®ä»˜è´¹APIå¯†é’¥æˆ–ç¨åé‡è¯•ã€‚\næœç´¢æŸ¥è¯¢: {query}"
