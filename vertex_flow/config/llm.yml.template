# Vertex Flow 统一配置模板
# 集成了LLM、MCP、向量存储、网络搜索等所有功能的配置
# 通过docker env可以注入相关的配置，作为修改值
# 例如llm.deepseek.sk，则通过llm_deepseek_sk环境变量
# 在docker启动时设置-e llm_deepseek_sk=?
#
# 本地模型支持（Ollama）:
# 1. 安装Ollama: https://ollama.com/download
# 2. 启动服务: ollama serve
# 3. 拉取模型: ollama pull qwen:7b
# 4. 在应用中切换到ollama提供商

# ============================================================================
# 大语言模型配置 (LLM Configuration)
# ============================================================================
llm:
  deepseek:
    sk: ${llm.deepseek.sk:-YOUR_DEEPSEEK_API_KEY}
    enabled: ${llm.deepseek.enabled:false}
    base_url: ${llm.deepseek.base_url:https://api.deepseek.com}
    models:
      - name: deepseek-chat
        enabled: ${llm.deepseek.models.deepseek_chat.enabled:false}
      - name: deepseek-reason
        enabled: ${llm.deepseek.models.deepseek_coder.enabled:false}
  tongyi:
    sk: ${llm.tongyi.sk:-YOUR_TONGYI_API_KEY}
    enabled: ${llm.tongyi.enabled:false}
    base_url: ${llm.tongyi.base_url:https://dashscope.aliyuncs.com/compatible-mode/v1}
    models:
      - name: qwen-vl-max
        enabled: ${llm.tongyi.models.qwen_vl_max.enabled:false}
      - name: qwen-max
        enabled: ${llm.tongyi.models.qwen_max.enabled:true}
      - name: qwen-plus
        enabled: ${llm.tongyi.models.qwen_plus.enabled:false}
      - name: qwen-turbo
        enabled: ${llm.tongyi.models.qwen_turbo.enabled:false}
  openrouter:
    sk: ${llm.openrouter.sk:-YOUR_OPENROUTER_API_KEY}
    enabled: ${llm.openrouter.enabled:false}
    base_url: ${llm.openrouter.base_url:https://openrouter.ai/api/v1}
    models:
      - name: deepseek/deepseek-chat-v3-0324:free
        enabled: ${llm.openrouter.models.deepseek_chat_v3_0324.enabled:false}
      - name: deepseek/deepseek-r1-0528:free
        enabled: ${llm.openrouter.models.deepseek_r1_0528.enabled:true}
      - name: google/gemini-2.5-pro
        enabled: ${llm.openrouter.models.gemini_2_5_pro.enabled:true}
      - name: anthropic/claude-3.5-sonnet
        enabled: ${llm.openrouter.models.claude_3_5_sonnet.enabled:false}
      - name: openai/gpt-4o
        enabled: ${llm.openrouter.models.gpt_4o.enabled:false}
  ollama:
    sk: ${llm.ollama.sk:-ollama-local}          # 本地模型不需要真实API key，使用占位符
    enabled: ${llm.ollama.enabled:-false}       # 默认不启用，需要手动切换
    base-url: ${llm.ollama.base_url:http://localhost:11434}  # Ollama服务地址
    models:
      - name: qwen:7b
        enabled: ${llm.ollama.models.qwen_7b.enabled:true}
      - name: llama3:8b
        enabled: ${llm.ollama.models.llama3_8b.enabled:false}
      - name: mistral:7b
        enabled: ${llm.ollama.models.mistral_7b.enabled:false}
  doubao:
    sk: ${llm.doubao.sk:-YOUR_DOUBAO_API_KEY}
    enabled: ${llm.doubao.enabled:-false}
    base_url: ${llm.doubao.base_url:https://ark.cn-beijing.volces.com/api/v3}
    models:
      - name: doubao-seed-1.6-250615
        enabled: ${llm.doubao.models.doubao_seed_1_6_250615.enabled:true}
      - name: doubao-seed-1.6-thinking-250615
        enabled: ${llm.doubao.models.doubao_seed_1_6_thinking_250615.enabled:false}
      - name: doubao-seed-1.6-flash-250615
        enabled: ${llm.doubao.models.doubao_seed_1_6_flash_250615.enabled:false}
  
  # 其他自定义LLM提供商配置
  # 支持每个模型单独配置provider、model name和base_url
  # 适用于自定义API端点、私有部署模型等场景
  other:
    enabled: ${llm.other.enabled:-false}  # 默认不启用
    models:
      # 示例：SiliconFlow Qwen/QwQ-32B模型
      - name: Qwen/QwQ-32B
        enabled: ${llm.other.models.qwen_qwq_32b.enabled:false}
        provider: "siliconflow"
        base_url: ${llm.other.qwen_qwq_32b.base_url:-https://api.siliconflow.cn/v1}
        sk: ${llm.other.qwen_qwq_32b.sk:-YOUR_SILICONFLOW_API_KEY}
      
      # 示例：自定义OpenAI兼容API
      - name: custom-model-1
        enabled: ${llm.other.models.custom_model_1.enabled:false}
        provider: "custom-openai"
        base_url: ${llm.other.custom_model_1.base_url:-https://your-custom-api.com/v1}
        sk: ${llm.other.custom_model_1.sk:-YOUR_CUSTOM_API_KEY}
      
      # 示例：私有部署的模型
      - name: private-llama
        enabled: ${llm.other.models.private_llama.enabled:false}
        provider: "private-deployment"
        base_url: ${llm.other.private_llama.base_url:-http://localhost:8000/v1}
        sk: ${llm.other.private_llama.sk:-your-private-key}
      
      # 示例：第三方API服务
      - name: third-party-model
        enabled: ${llm.other.models.third_party_model.enabled:false}
        provider: "third-party"
        base_url: ${llm.other.third_party_model.base_url:-https://api.thirdparty.com/v1}
        sk: ${llm.other.third_party_model.sk:-YOUR_THIRD_PARTY_API_KEY}
      
      # 示例：本地部署的模型服务
      - name: local-model
        enabled: ${llm.other.models.local_model.enabled:false}
        provider: "local"
        base_url: ${llm.other.local_model.base_url:-http://127.0.0.1:8080/v1}
        sk: ${llm.other.local_model.sk:-local-key}

web-search:
  # Bocha AI搜索服务 - 高质量AI总结，支持日期过滤
  bocha:
    sk: ${web-search.bocha.sk:-YOUR_BOCHA_API_KEY}
    enabled: false  # 需要API密钥，提供最佳搜索体验
  
  # DuckDuckGo搜索服务 - 免费即时答案，无需API密钥
  duckduckgo:
    enabled: true  # 默认启用，作为免费备选方案
  
  # SerpAPI搜索服务 - Google搜索结果，免费层每月100次
  serpapi:
    api_key: ${web-search.serpapi.api_key:-YOUR_SERPAPI_API_KEY}
    enabled: false  # 需要API密钥，提供Google搜索结果
  
  # SearchAPI.io搜索服务 - 多搜索引擎支持，免费层每月100次
  searchapi:
    api_key: ${web-search.searchapi.api_key:-YOUR_SEARCHAPI_API_KEY}
    enabled: false  # 需要API密钥，支持多种搜索引擎
  
  # Brave Search API服务 - 隐私保护的搜索引擎，需要API密钥
  brave:
    api_key: ${web-search.brave.api_key:-YOUR_BRAVE_API_KEY}
    enabled: false  # 需要API密钥，提供隐私保护的搜索结果
  
  # 注意：以上搜索服务按优先级排序，系统会自动选择第一个启用且配置正确的服务
  # 建议配置：启用Bocha AI（付费，最佳体验）+ DuckDuckGo（免费备选）
  
  # 已废弃的配置（保留以兼容旧版本）
  bing:
    sk: ${web-search.bing.sk:-YOUR_BING_API_KEY}
    enabled: false

# 金融工具配置
finance:
  alpha-vantage:
    api-key: ${finance.alpha-vantage.api-key:-YOUR_ALPHA_VANTAGE_API_KEY}
    enabled: false
  finnhub:
    api-key: ${finance.finnhub.api-key:-YOUR_FINNHUB_API_KEY}
    enabled: false
  yahoo-finance:
    enabled: true

workflow:
  dify:
    root-path: config/
    instances:

web:
  port: 8999
  host: 0.0.0.0
  workers: 8

# 向量存储配置（支持本地和云端）
vector:
  # 本地向量存储配置
  local:
    enabled: true  # 默认启用本地向量存储
    dimension: 384  # 向量维度
    index_name: "default"  # 索引名称
    persist_dir: null  # 持久化目录，null表示使用默认目录 (~/.vertex_flow/vector_db)
  
  # DashVector云端配置
  dashvector:
    enabled: false  # 默认不启用云端
    api-key: ${vector.dashvector.api_key:-YOUR_DASHVECTOR_API_KEY}
    endpoint: ${vector.dashvector.endpoint:-YOUR_DASHVECTOR_ENDPOINT}
    cluster: ${vector.dashvector.cluster:-vertex-vector}
    collection: ${vector.dashvector.collection:-YOUR_COLLECTION_NAME}
    image-collection: ${vector.dashvector.image_collection:-YOUR_IMAGE_COLLECTION_NAME}

# 嵌入模型配置（支持本地和云端）
embedding:
  # 本地嵌入模型配置
  local:
    enabled: true  # 默认启用本地嵌入
    model_name: "all-MiniLM-L6-v2"  # 本地嵌入模型名称
    dimension: 384  # 向量维度
    use_mirror: true  # 是否使用国内镜像源（默认true）
    mirror_url: "https://hf-mirror.com"  # 镜像源URL
  
  # DashScope云端配置
  dashscope:
    enabled: false  # 默认不启用云端
    endpoint: ${embedding.dashscope.endpoint:-default}
    api-key: ${embedding.dashscope.api_key:-YOUR_DASHSCOPE_API_KEY}
    model-name: ${embedding.dashscope.model_name:-text-embedding-v1}
  
  # BCE云端配置
  bce:
    enabled: false  # 默认不启用云端
    api-key: ${embedding.bce.api_key:-YOUR_BCE_API_KEY}
    endpoint: ${embedding.bce.endpoint:-https://api.siliconflow.cn/v1/embeddings}
    model-name: ${embedding.bce.model_name:-netease-youdao/bce-embedding-base_v1}
    dimension: 768  # BCE 嵌入模型维度

# 重排序配置
rerank:
  # 本地重排序配置
  local:
    enabled: false  # 默认不启用本地重排序
    method: "keyword"  # 重排序方法：keyword, semantic
  
  # BCE云端重排序配置
  bce:
    enabled: false  # 默认不启用云端重排序
    api-key: ${rerank.bce.api_key:-YOUR_BCE_RERANK_API_KEY}
    endpoint: ${rerank.bce.endpoint:-https://api.siliconflow.cn/v1/rerank}
    model-name: ${rerank.bce.model_name:-netease-youdao/bce-reranker-base_v1}

# 文档处理配置
document:
  chunk_size: 512  # 文档分块大小，与 BCE 嵌入 API 的 token 限制一致
  chunk_overlap: 128  # 分块重叠大小
  supported_formats: ["txt", "md", "pdf", "docx"]  # 支持的文档格式

# 检索配置
retrieval:
  top_k: 3  # 检索的文档数量
  similarity_threshold: 0.7  # 相似度阈值
  rerank: false  # 是否启用重排序

# ============================================================================
# MCP (Model Context Protocol) 配置
# ============================================================================
# MCP提供统一的工具调用接口，支持连接外部MCP服务器和暴露内部工具
# 
# 可用的内置工具列表：
# 1. 命令行工具 (execute_command) - 执行系统命令
# 2. 网络搜索工具 (web_search_*) - 支持多个搜索引擎
#    - web_search_bocha: 博查搜索
#    - web_search_duckduckgo: DuckDuckGo搜索
#    - web_search_serpapi: SerpAPI搜索
#    - web_search_searchapi: SearchAPI搜索
#    - web_search_bing: Bing搜索
# 3. 金融工具 (finance_tool) - 获取股票、汇率等金融数据
# 4. 时间工具:
#    - today: 获取当前日期时间
#    - time_convert: 时间格式转换
#    - time_diff: 计算时间差
# 5. 自定义工具:
#    - calculate: 数学计算器
#    - process_text: 文本处理工具
#
# MCP工具调用格式：
# 在对话中，AI可以自动调用这些工具，例如：
# - "帮我搜索最新的AI新闻" -> 自动调用web_search工具
# - "执行ls命令" -> 自动调用execute_command工具
# - "查询苹果股票价格" -> 自动调用finance_tool工具
# - "现在几点了" -> 自动调用today工具
# - "计算2+2" -> 自动调用calculate工具
#
mcp:
  # Enable MCP integration
  enabled: true
  
  # MCP Clients - Connect to external MCP servers
  clients:
    # Filesystem server for file access
    filesystem:
      enabled: true
      transport: "stdio"
      command: "npx"
      args:
        - "@modelcontextprotocol/server-filesystem"
        - "/path/to/your/workspace"  # 修改为你的工作目录
    
    # Everything server for testing tools
    everything:
      enabled: true
      transport: "stdio"
      command: "npx"
      args:
        - "-y"
        - "@modelcontextprotocol/server-everything"
    
    # Lark MCP client for chat history and document access
    # 使用说明：
    # 1. 在飞书开放平台创建应用获取APP_ID和APP_SECRET
    # 2. 设置环境变量：export LARK_APP_ID=your_app_id
    # 3. 设置环境变量：export LARK_APP_SECRET=your_app_secret
    # 4. 将enabled改为true启用
    # Lark MCP client for chat history and document access
    # 使用说明：
    # 1. 在飞书开放平台创建应用获取APP_ID和APP_SECRET
    # 2. 设置环境变量：export LARK_APP_ID=your_app_id 和 export LARK_APP_SECRET=your_app_secret
    # 3. 将enabled改为true启用
    # 可用功能：聊天记录访问、消息发送、文档内容读取、多维表格搜索
    lark:
      enabled: false  # 默认禁用，需要配置环境变量后手动启用
      transport: "stdio"
      command: "lark-mcp"
      args:
        - "mcp"
        - "-a"
        - "${LARK_APP_ID:-your-lark-app-id}"
        - "-s"
        - "${LARK_APP_SECRET:-your-lark-app-secret}"
        - "--oauth"
        - "-c"
        - "snake"
        - "-t"
        - "im.v1.message.create,im.v1.message.list,im.v1.chat.list,im.v1.chat.create,im.v1.chat.search,im.v1.chatMembers.get,docx.v1.document.rawContent,bitable.v1.appTableRecord.search,docx.builtin.search,contact.v3.user.batchGetId,wiki.v2.space.getNode,wiki.v1.node.search,docx.builtin.import"
      env:
        LARK_APP_ID: "${LARK_APP_ID:-}"
        LARK_APP_SECRET: "${LARK_APP_SECRET:-}"
      description: "Access Lark chat history, messages, documents and Bitable records"
    
    # GitHub MCP client for repository access
    # 使用说明：
    # 1. 在GitHub创建Personal Access Token
    # 2. 设置环境变量：export GITHUB_PERSONAL_ACCESS_TOKEN=your_token
    # 3. 将enabled改为true启用
    # 可用功能：仓库访问、Issue管理、Pull Request操作、文件读写
    github:
      enabled: false
      transport: "stdio"
      command: "npx"
      args: ["@modelcontextprotocol/server-github"]
      env:
        GITHUB_PERSONAL_ACCESS_TOKEN: "${GITHUB_PERSONAL_ACCESS_TOKEN:-your-github-token}"
      description: "Access GitHub repositories and issues"
    
    # Database MCP client for database access
    # 使用说明：
    # 1. 安装数据库MCP服务器：pip install mcp-server-database
    # 2. 修改connection-string为你的数据库连接字符串
    # 3. 将enabled改为true启用
    # 支持：SQLite、MySQL、PostgreSQL等数据库
    database:
      enabled: false
      transport: "stdio"
      command: "python"
      args: ["-m", "mcp_server_database", "--connection-string", "sqlite:///your_database.db"]
      description: "Access database resources"
    
    # Web Search MCP client (独立于内置搜索)
    # 使用说明：
    # 1. 安装搜索MCP服务器：pip install mcp-server-web-search
    # 2. 设置环境变量：export SEARCH_API_KEY=your_api_key
    # 3. 将enabled改为true启用
    # 提供额外的网络搜索能力，补充内置搜索功能
    mcp_web_search:
      enabled: false
      transport: "stdio"
      command: "python"
      args: ["-m", "mcp_server_web_search"]
      env:
        SEARCH_API_KEY: "${SEARCH_API_KEY:-your-search-api-key}"
      description: "MCP-based web search capabilities"
    
    # HTTP MCP client for远程MCP服务器连接
    # 使用说明：
    # 1. 确保远程MCP服务器正在运行
    # 2. 修改base_url为实际的服务器地址
    # 3. 将enabled改为true启用
    # 用于连接通过HTTP协议提供的MCP服务
    http_server:
      enabled: false
      transport: "http"
      base_url: "http://localhost:8080"
      description: "Connect to HTTP MCP server"
  
  # MCP Server - 暴露Vertex Flow资源和工具给外部MCP客户端
  # 使用说明：
  # 1. 启用后可以将Vertex Flow作为MCP服务器供其他应用使用
  # 2. stdio传输适用于命令行集成
  # 3. HTTP传输适用于Web应用集成
  # 4. 可以选择性暴露工作流、文档、配置等资源
  server:
    enabled: true
    name: "VertexFlow"
    version: "1.0.0"
    
    # Server transport configuration
    transport:
      # stdio transport (for command-line usage)
      stdio:
        enabled: true
      
      # HTTP transport (for web-based usage)
      http:
        enabled: false
        host: "localhost"
        port: 8080
    
    # Resources to expose
    resources:
      enabled: true
      # Expose workflow configurations
      workflows:
        enabled: true
        path: "vertex_flow/workflow"
        pattern: "*.py"
      
      # Expose documentation
      docs:
        enabled: true
        path: "docs"
        pattern: "*.md"
      
      # Expose configuration files
      configs:
        enabled: true
        path: "vertex_flow/config"
        pattern: "*.yml"
    
    # Tools to expose - 暴露给外部MCP客户端的工具
    tools:
      enabled: true
      
      # Expose function tools - 暴露功能工具
      # 包含所有内置工具：命令行、网络搜索、金融、时间、计算等
      function_tools:
        enabled: true
        # Auto-discover function tools - 自动发现所有可用工具
        auto_discover: true
        # Specific function tools to expose - 指定要暴露的工具
        # 可用工具列表：
        # - execute_command: 命令行执行
        # - web_search_*: 各种搜索引擎
        # - finance_tool: 金融数据查询
        # - today: 当前时间
        # - time_convert: 时间转换
        # - time_diff: 时间差计算
        # - calculate: 数学计算
        # - process_text: 文本处理
        include:
          - "web_search"
          - "command_line"
          - "finance"
          - "today"
          - "calculate"
      
      # Expose workflow execution - 暴露工作流执行能力
      workflow_execution:
        enabled: true
        description: "Execute Vertex Flow workflows"
      
      # Expose vertex operations - 暴露顶点操作能力
      vertex_operations:
        enabled: true
        description: "Perform vertex-level operations"
    
    # Prompts to expose
    prompts:
      enabled: true
      
      # System prompts
      system_prompts:
        enabled: true
        path: "vertex_flow/prompts/system"
      
      # Task-specific prompts
      task_prompts:
        enabled: true
        path: "vertex_flow/prompts/tasks"
      
      # Custom prompts
      custom_prompts:
        - name: "code_review"
          template: |
            Please review the following code and provide feedback:
            
            Code:
            {code}
            
            Focus areas: {focus_areas}
            
            Please provide:
            1. Overall assessment
            2. Potential issues
            3. Improvement suggestions
            4. Best practices recommendations
          description: "Code review prompt with focus areas"
          arguments:
            - name: "code"
              description: "Code to review"
              required: true
            - name: "focus_areas"
              description: "Specific areas to focus on (security, performance, etc.)"
              required: false
        
        - name: "workflow_design"
          template: |
            Design a Vertex Flow workflow for the following requirements:
            
            Requirements:
            {requirements}
            
            Constraints:
            {constraints}
            
            Please provide:
            1. Workflow structure
            2. Vertex configuration
            3. Data flow design
            4. Error handling strategy
          description: "Workflow design assistance"
          arguments:
            - name: "requirements"
              description: "Workflow requirements"
              required: true
            - name: "constraints"
              description: "Technical or business constraints"
              required: false

# ============================================================================
# MCP集成设置 (MCP Integration Settings)
# ============================================================================
integration:
  # Auto-connect to MCP clients on startup
  auto_connect: true
  
  # Timeout for MCP operations (seconds)
  timeout: 30
  
  # Retry configuration
  retry:
    max_attempts: 3
    delay: 1.0
    backoff_factor: 2.0
  
  # Logging configuration
  logging:
    level: "INFO"
    log_mcp_messages: false
    log_tool_calls: true
  
  # Security settings
  security:
    # Require explicit approval for tool calls
    require_approval: false
    
    # Allowed resource patterns
    allowed_resources:
      - "file://*"
      - "workflow://*"
      - "config://*"
    
    # Blocked resource patterns
    blocked_resources:
      - "file:///etc/*"
      - "file:///root/*"
    
    # Tool execution limits
    tool_limits:
      max_execution_time: 60  # seconds
      max_memory_usage: 100   # MB