#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦ç ”ç©¶å·¥ä½œæµ Gradio åº”ç”¨
åŸºäº DeepResearchWorkflow çš„äº¤äº’å¼æ·±åº¦ç ”ç©¶åˆ†æå·¥å…·
"""

import argparse
import asyncio
import json
import os
import re
import sys
import threading
from datetime import datetime
from typing import Any, Dict, List, Tuple

import gradio as gr

from vertex_flow.utils.logger import setup_logger
from vertex_flow.workflow.app.deep_research_workflow import DeepResearchWorkflow
from vertex_flow.workflow.service import VertexFlowService
from vertex_flow.workflow.event_channel import EventType
from vertex_flow.workflow.constants import WORKFLOW_COMPLETE, WORKFLOW_FAILED

# é…ç½®æ—¥å¿—
logger = setup_logger(__name__)


class DeepResearchApp:
    """æ·±åº¦ç ”ç©¶å·¥ä½œæµ Gradio åº”ç”¨"""
    
    # ç±»å¸¸é‡ï¼šé˜¶æ®µæ˜ å°„é…ç½®
    STAGE_MAPPING = {
        "topic_analysis": ("ä¸»é¢˜åˆ†æ", "ğŸ”"),
        "research_planning": ("ç ”ç©¶è§„åˆ’", "ğŸ“‹"),
        "information_collection": ("ä¿¡æ¯æ”¶é›†", "ğŸ“š"),
        "deep_analysis": ("æ·±åº¦åˆ†æ", "ğŸ”¬"),
        "cross_validation": ("äº¤å‰éªŒè¯", "âœ…"),
        "summary_report": ("æ€»ç»“æŠ¥å‘Š", "ğŸ“„")
    }
    
    # é˜¶æ®µé¡ºåºåˆ—è¡¨
    STAGE_ORDER = ["topic_analysis", "research_planning", "information_collection", 
                   "deep_analysis", "cross_validation", "summary_report"]
    
    # Markdownæ£€æµ‹æ¨¡å¼
    MARKDOWN_PATTERNS = [
        r'^#+\s',           # æ ‡é¢˜ # ## ###
        r'\*\*.*\*\*',      # ç²—ä½“ **text**
        r'\*.*\*',          # æ–œä½“ *text*
        r'^-\s+',           # åˆ—è¡¨é¡¹ - item
        r'^\d+\.\s+',       # ç¼–å·åˆ—è¡¨ 1. item
        r'\[.*\]\(.*\)',    # é“¾æ¥ [text](url)
        r'```',             # ä»£ç å— ```
        r'`.*`',            # è¡Œå†…ä»£ç  `code`
        r'^\|.*\|',         # è¡¨æ ¼ |col1|col2|
        r'^>',              # å¼•ç”¨ > text
    ]
    
    # ç•Œé¢å¸¸é‡
    CONTENT_PREVIEW_LENGTH = 2000  # å†…å®¹é¢„è§ˆé•¿åº¦
    STREAM_CONTENT_LENGTH = 1500   # æµå¼å†…å®¹æ˜¾ç¤ºé•¿åº¦
    FINAL_REPORT_MIN_LENGTH = 100  # æœ€ç»ˆæŠ¥å‘Šæœ€å°é•¿åº¦
    LONG_TEXT_MIN_LENGTH = 100     # é•¿æ–‡æœ¬æœ€å°é•¿åº¦
    
    def __init__(self, config_path: str = None):
        """åˆå§‹åŒ–åº”ç”¨"""
        try:
            # ä½¿ç”¨æä¾›çš„é…ç½®è·¯å¾„æˆ–é»˜è®¤é…ç½®
            if config_path is None:
                # ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤é…ç½®è·¯å¾„
                from vertex_flow.workflow.utils import default_config_path
                config_path = default_config_path("llm.yml")
                logger.info(f"ä½¿ç”¨é»˜è®¤é…ç½®è·¯å¾„: {config_path}")
            else:
                config_path = os.path.abspath(config_path)
                logger.info(f"ä½¿ç”¨æŒ‡å®šé…ç½®è·¯å¾„: {config_path}")
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(config_path):
                raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            
            self.service = VertexFlowService(config_path)
            self.workflow_builder = DeepResearchWorkflow(self.service)
            self.current_workflow = None
            
            # åˆå§‹åŒ–é˜¶æ®µå†å²è®°å½•
            self.stage_history = {}
            self.completed_stages = set()
            self.current_research_topic = ""
            self.workflow_running = False
            
            self._initialize_llm()
            logger.info("Deep Research åº”ç”¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Deep Research åº”ç”¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _initialize_llm(self):
        """åˆå§‹åŒ– LLM æ¨¡å‹"""
        try:
            self.llm_model = self.service.get_chatmodel()
            if self.llm_model is None:
                raise ValueError("æ— æ³•è·å–èŠå¤©æ¨¡å‹ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")
            
            try:
                model_name = self.llm_model.model_name()
            except:
                model_name = str(self.llm_model)
            
            logger.info(f"æˆåŠŸåˆå§‹åŒ–èŠå¤©æ¨¡å‹: {model_name}")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ– LLM å¤±è´¥: {e}")
            raise
    
    def start_research(self, research_topic: str, save_intermediate: bool, save_final_report: bool, enable_stream: bool):
        """å¼€å§‹æ·±åº¦ç ”ç©¶"""
        if not research_topic.strip():
            yield "âŒ è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜", "", "", [], gr.update()
            return
        
        try:
            # é‡ç½®é˜¶æ®µå†å²è®°å½•
            self.stage_history = {}
            self.completed_stages = set()
            self.current_research_topic = research_topic.strip()
            self.workflow_running = True
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                "content": research_topic.strip(),
                "stream": enable_stream,
                "save_intermediate": save_intermediate,
                "save_final_report": save_final_report,
                "env_vars": {},
                "user_vars": {}
            }
            
            logger.info(f"å¼€å§‹æ·±åº¦ç ”ç©¶: {research_topic}")
            
            # åˆ›å»ºå·¥ä½œæµ
            self.current_workflow = self.workflow_builder.create_workflow(input_data)
            
            if enable_stream:
                yield from self._execute_workflow_stream(input_data, research_topic)
            else:
                yield from self._execute_workflow_batch(input_data, research_topic)
                
        except Exception as e:
            error_msg = f"ç ”ç©¶æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            yield error_msg, "", "", [], gr.update()
    
    def _execute_workflow_stream(self, input_data: Dict[str, Any], research_topic: str):
        """æµå¼æ‰§è¡Œå·¥ä½œæµ"""
        try:
            # å…ˆæ‰§è¡Œå·¥ä½œæµï¼ˆåœ¨åå°çº¿ç¨‹ä¸­ï¼‰
            def run_workflow():
                try:
                    self.current_workflow.execute_workflow(input_data, stream=True)
                except Exception as e:
                    logger.error(f"å·¥ä½œæµæ‰§è¡Œé”™è¯¯: {e}")
            
            # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨å·¥ä½œæµ
            workflow_thread = threading.Thread(target=run_workflow)
            workflow_thread.daemon = True
            workflow_thread.start()
            
            # æµå¼è·å–äº‹ä»¶
            yield from self._stream_workflow_events()
                
        except Exception as e:
            error_msg = f"âŒ æµå¼æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            yield error_msg, "æ‰§è¡Œå¤±è´¥", f"æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    def _stream_workflow_events(self):
        """æµå¼è·å–å·¥ä½œæµäº‹ä»¶"""
        # åˆå§‹åŒ–çŠ¶æ€
        progress_log = []
        current_stage = ""
        current_content = ""
        previous_stage_buttons = []
        
        def add_log(message):
            timestamp = datetime.now().strftime('%H:%M:%S')
            progress_log.append(f"[{timestamp}] {message}")
        
        # ä½¿ç”¨ç±»çš„è¾…åŠ©æ–¹æ³•
        create_stage_buttons = self._create_stage_buttons
        should_update_stage_selector = self._should_update_stage_selector
        
        add_log("ğŸš€ å¼€å§‹æ·±åº¦ç ”ç©¶åˆ†æ...")
        initial_buttons = create_stage_buttons()
        previous_stage_buttons = initial_buttons.copy()
        yield "ğŸš€ å¼€å§‹æ·±åº¦ç ”ç©¶åˆ†æ...", "å‡†å¤‡ä¸­", "\n".join(progress_log[-10:]), initial_buttons, gr.update()
        
        async def stream_events():
            nonlocal current_stage, current_content, previous_stage_buttons
            
            try:
                # ç›‘å¬å·¥ä½œæµäº‹ä»¶
                async for event in self.current_workflow.astream([EventType.MESSAGES, EventType.VALUES, EventType.UPDATES]):
                    event_type = type(event).__name__
                    logger.info(f"æ”¶åˆ°äº‹ä»¶ç±»å‹: {event_type}, å†…å®¹: {event}")
                    
                    # å¤„ç†æ¶ˆæ¯äº‹ä»¶ï¼ˆæµå¼è¾“å‡ºå†…å®¹ï¼‰
                    if 'vertex_id' in event and 'message' in event:
                        vertex_id = event['vertex_id']
                        message = event.get('message', '')
                        status = event.get('status', '')
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬å…³å¿ƒçš„é˜¶æ®µ
                        for stage_id, (stage_name, stage_icon) in self.STAGE_MAPPING.items():
                            if stage_id in vertex_id:
                                current_stage = f"{stage_icon} {stage_name}"
                                
                                if status == "start":
                                    add_log(f"å¼€å§‹ {stage_name}...")
                                    current_buttons = create_stage_buttons()
                                    stage_selector_update = gr.update(choices=current_buttons) if should_update_stage_selector(previous_stage_buttons, current_buttons) else gr.update()
                                    if should_update_stage_selector(previous_stage_buttons, current_buttons):
                                        previous_stage_buttons = current_buttons.copy()
                                    yield f"â³ æ­£åœ¨æ‰§è¡Œ: {stage_name}", current_stage, "\n".join(progress_log[-10:]), current_buttons, stage_selector_update
                                    break
                                elif status == "end":
                                    self.completed_stages.add(stage_id)
                                    add_log(f"å®Œæˆ {stage_name}")
                                    # è·å–å®Œæ•´å†…å®¹
                                    if stage_id in self.stage_history:
                                        current_content = self.stage_history[stage_id]['content']
                                        logger.info(f"é˜¶æ®µ {stage_name} å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(current_content)}")
                                    current_buttons = create_stage_buttons()
                                    stage_selector_update = gr.update(choices=current_buttons) if should_update_stage_selector(previous_stage_buttons, current_buttons) else gr.update()
                                    if should_update_stage_selector(previous_stage_buttons, current_buttons):
                                        previous_stage_buttons = current_buttons.copy()
                                    yield f"âœ… å®Œæˆ: {stage_name}", current_content[:2000] + "..." if len(current_content) > 2000 else current_content, "\n".join(progress_log[-10:]), current_buttons, stage_selector_update
                                    break
                                elif message:
                                    # ç´¯ç§¯å½“å‰é˜¶æ®µçš„å†…å®¹
                                    if stage_id not in self.stage_history:
                                        self.stage_history[stage_id] = {
                                            'name': stage_name,
                                            'icon': stage_icon,
                                            'content': "",
                                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                        }
                                    self.stage_history[stage_id]['content'] += message
                                    current_content = self.stage_history[stage_id]['content']
                                    
                                    # æ˜¾ç¤ºå®æ—¶å†…å®¹ï¼ˆé™åˆ¶é•¿åº¦é¿å…ç•Œé¢å¡é¡¿ï¼‰
                                    display_content = current_content[-1500:] if len(current_content) > 1500 else current_content
                                    
                                    # ä¸ºæµå¼å†…å®¹æ·»åŠ markdownæ ¼å¼æç¤º
                                    if display_content.strip():
                                        # æ£€æµ‹æ˜¯å¦ä¸ºmarkdownå†…å®¹
                                        if len(display_content) > 50 and any(re.search(pattern, display_content, re.MULTILINE) for pattern in self.MARKDOWN_PATTERNS):
                                            # å¯èƒ½æ˜¯markdownï¼Œæ·»åŠ é€‚å½“çš„æ ¼å¼
                                            formatted_display = f"### ğŸ“ {stage_name} è¿›è¡Œä¸­...\n\n{display_content}"
                                        else:
                                            # æ™®é€šæ–‡æœ¬ï¼Œç”¨ä»£ç å—æ ¼å¼æ˜¾ç¤º
                                            formatted_display = f"### ğŸ“ {stage_name} è¿›è¡Œä¸­...\n\n```\n{display_content}\n```"
                                    else:
                                        formatted_display = f"### ğŸ“ {stage_name} è¿›è¡Œä¸­...\n\næ­£åœ¨ç”Ÿæˆå†…å®¹..."
                                    
                                    current_buttons = create_stage_buttons()
                                    stage_selector_update = gr.update(choices=current_buttons) if should_update_stage_selector(previous_stage_buttons, current_buttons) else gr.update()
                                    if should_update_stage_selector(previous_stage_buttons, current_buttons):
                                        previous_stage_buttons = current_buttons.copy()
                                    yield f"â³ æ­£åœ¨æ‰§è¡Œ: {stage_name}", formatted_display, "\n".join(progress_log[-10:]), current_buttons, stage_selector_update
                                    break
                    
                    # å¤„ç†çŠ¶æ€äº‹ä»¶
                    elif 'status' in event:
                        status = event['status']
                        if status == WORKFLOW_COMPLETE:
                            self.workflow_running = False
                            add_log("âœ… æ·±åº¦ç ”ç©¶å®Œæˆ!")
                            # è·å–æœ€ç»ˆç»“æœ
                            results = self.current_workflow.result()
                            logger.debug(f"å·¥ä½œæµç»“æœ: {results}")
                            
                            if results and 'sink' in results:
                                final_report = results['sink'].get('final_report', 'æ²¡æœ‰ç”ŸæˆæŠ¥å‘Š')
                                file_path = results['sink'].get('file_path', '')
                                
                                if file_path:
                                    add_log(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {file_path}")
                                
                                logger.debug(f"æœ€ç»ˆæŠ¥å‘Šé•¿åº¦: {len(final_report)}")
                                current_buttons = create_stage_buttons()
                                yield "âœ… æ·±åº¦ç ”ç©¶å®Œæˆ!", final_report, "\n".join(progress_log[-10:]), current_buttons, gr.update(choices=current_buttons)
                            else:
                                # å°è¯•ä»é˜¶æ®µå†å²ä¸­è·å–æœ€ç»ˆæŠ¥å‘Š
                                if 'summary_report' in self.stage_history:
                                    final_report = self.stage_history['summary_report']['content']
                                    add_log(f"ä»é˜¶æ®µå†å²è·å–æœ€ç»ˆæŠ¥å‘Šï¼Œé•¿åº¦: {len(final_report)}")
                                    current_buttons = create_stage_buttons()
                                    yield "âœ… æ·±åº¦ç ”ç©¶å®Œæˆ!", final_report, "\n".join(progress_log[-10:]), current_buttons, gr.update(choices=current_buttons)
                                else:
                                    current_buttons = create_stage_buttons()
                                    yield "âŒ å·¥ä½œæµæ‰§è¡Œå®Œæˆä½†æ²¡æœ‰è·å–åˆ°ç»“æœ", "", "\n".join(progress_log), current_buttons, gr.update(choices=current_buttons)
                            break
                        elif status == WORKFLOW_FAILED:
                            self.workflow_running = False
                            add_log("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥")
                            current_buttons = create_stage_buttons()
                            yield "âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥", "", "\n".join(progress_log[-10:]), current_buttons, gr.update(choices=current_buttons)
                            break
                    
                    # å¤„ç†å€¼äº‹ä»¶ï¼ˆé¡¶ç‚¹è¾“å‡ºï¼‰
                    elif 'vertex_id' in event and 'output' in event:
                        vertex_id = event['vertex_id']
                        output = event.get('output', '')
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬å…³å¿ƒçš„é˜¶æ®µ
                        for stage_id, (stage_name, stage_icon) in self.STAGE_MAPPING.items():
                            if stage_id in vertex_id and output:
                                # ä¿å­˜åˆ°é˜¶æ®µå†å²è®°å½•
                                self.stage_history[stage_id] = {
                                    'name': stage_name,
                                    'icon': stage_icon,
                                    'content': output,
                                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                }
                                self.completed_stages.add(stage_id)
                                
                                # æ˜¾ç¤ºé˜¶æ®µå®Œæˆçš„å†…å®¹
                                display_content = output[:2000] + "..." if len(output) > 2000 else output
                                add_log(f"âœ… {stage_name} ç”Ÿæˆäº† {len(output)} å­—ç¬¦çš„å†…å®¹")
                                current_buttons = create_stage_buttons()
                                stage_selector_update = gr.update(choices=current_buttons) if should_update_stage_selector(previous_stage_buttons, current_buttons) else gr.update()
                                if should_update_stage_selector(previous_stage_buttons, current_buttons):
                                    previous_stage_buttons = current_buttons.copy()
                                yield f"âœ… å®Œæˆ: {stage_name}", display_content, "\n".join(progress_log[-10:]), current_buttons, stage_selector_update
                                break
                    
            except Exception as e:
                logger.error(f"äº‹ä»¶æµå¤„ç†é”™è¯¯: {e}")
                add_log(f"âŒ äº‹ä»¶å¤„ç†é”™è¯¯: {str(e)}")
                current_buttons = create_stage_buttons()
                yield f"âŒ äº‹ä»¶å¤„ç†é”™è¯¯: {str(e)}", "", "\n".join(progress_log[-10:]), current_buttons, gr.update(choices=current_buttons)
        
        # è¿è¡Œå¼‚æ­¥äº‹ä»¶æµ
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            async def run_stream():
                async for result in stream_events():
                    yield result
            
            # ç”±äºGradioéœ€è¦åŒæ­¥ç”Ÿæˆå™¨ï¼Œæˆ‘ä»¬éœ€è¦åŒæ­¥è¿è¡Œå¼‚æ­¥ä»£ç 
            async_gen = run_stream()
            
            async def get_next():
                try:
                    return await async_gen.__anext__()
                except StopAsyncIteration:
                    return None
            
            while True:
                try:
                    result = loop.run_until_complete(get_next())
                    if result is None:
                        break
                    yield result
                except Exception as e:
                    logger.error(f"äº‹ä»¶å¾ªç¯é”™è¯¯: {e}")
                    break
                    
        except Exception as e:
            logger.error(f"å¼‚æ­¥äº‹ä»¶æµé”™è¯¯: {e}")
            yield f"âŒ å¼‚æ­¥å¤„ç†é”™è¯¯: {str(e)}", "", f"å¼‚æ­¥å¤„ç†é”™è¯¯: {str(e)}", [], gr.update()
        finally:
            try:
                loop.close()
            except:
                pass
    
    def _execute_workflow_batch(self, input_data: Dict[str, Any], research_topic: str):
        """æ‰¹é‡æ‰§è¡Œå·¥ä½œæµ"""
        try:
            status_msg = "ğŸš€ å¼€å§‹æ·±åº¦ç ”ç©¶åˆ†æ..."
            yield status_msg, "å‡†å¤‡ä¸­...", "å¼€å§‹æ‰§è¡Œæ·±åº¦ç ”ç©¶å·¥ä½œæµ", [], gr.update()
            
            # æ‰§è¡Œå·¥ä½œæµ
            self.current_workflow.execute_workflow(input_data, stream=False)
            
            # è·å–ç»“æœ
            results = self.current_workflow.result()
            
            if results and 'sink' in results:
                final_report = results['sink'].get('final_report', 'æ²¡æœ‰ç”ŸæˆæŠ¥å‘Š')
                file_path = results['sink'].get('file_path', '')
                
                completion_msg = "âœ… æ·±åº¦ç ”ç©¶å®Œæˆ!"
                if file_path:
                    completion_msg += f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {file_path}"
                
                yield completion_msg, final_report, f"ç ”ç©¶å®Œæˆï¼Œç”Ÿæˆäº† {len(final_report)} å­—ç¬¦çš„æŠ¥å‘Š", [], gr.update()
            else:
                yield "âŒ å·¥ä½œæµæ‰§è¡Œå®Œæˆä½†æ²¡æœ‰è·å–åˆ°ç»“æœ", "", "æ‰§è¡Œå®Œæˆä½†ç»“æœä¸ºç©º", [], gr.update()
                
        except Exception as e:
            error_msg = f"âŒ æ‰¹é‡æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            yield error_msg, "", f"æ‰§è¡Œå¤±è´¥: {str(e)}", [], gr.update()
    
    def get_workflow_status(self):
        """è·å–å½“å‰å·¥ä½œæµçŠ¶æ€"""
        if self.current_workflow:
            try:
                status = self.current_workflow.status()
                return f"å·¥ä½œæµçŠ¶æ€: {status}"
            except:
                return "æ— æ³•è·å–å·¥ä½œæµçŠ¶æ€"
        return "æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„å·¥ä½œæµ"
    
    def get_stage_content(self, stage_button_text: str) -> str:
        """æ ¹æ®é˜¶æ®µæŒ‰é’®æ–‡æœ¬è·å–é˜¶æ®µå†…å®¹"""
        logger.debug(f"è¯·æ±‚æŸ¥çœ‹é˜¶æ®µ: {stage_button_text}")
        logger.debug(f"å½“å‰é˜¶æ®µå†å²: {list(self.stage_history.keys())}")
        
        if not stage_button_text or not self.stage_history:
            return "è¯·å…ˆè¿è¡Œæ·±åº¦ç ”ç©¶å·¥ä½œæµ"
        
        # è§£ææŒ‰é’®æ–‡æœ¬ï¼Œæå–é˜¶æ®µåç§°
        for stage_id, stage_info in self.stage_history.items():
            expected_button_text = f"{stage_info['icon']} {stage_info['name']}"
            logger.debug(f"æ¯”è¾ƒ: '{expected_button_text}' vs '{stage_button_text}'")
            
            if expected_button_text == stage_button_text:
                logger.debug(f"æ‰¾åˆ°é˜¶æ®µå†…å®¹ï¼Œé•¿åº¦: {len(stage_info['content'])}")
                return self._format_stage_content(stage_info, include_metadata=True)
        
        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
        for stage_id, stage_info in self.stage_history.items():
            if stage_info['name'] in stage_button_text or stage_button_text in stage_info['name']:
                logger.debug(f"æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°é˜¶æ®µå†…å®¹: {stage_info['name']}")
                return self._format_stage_content(stage_info, include_metadata=True)
        
        # è¿”å›è°ƒè¯•ä¿¡æ¯
        available_stages = [f"{info['icon']} {info['name']}" for info in self.stage_history.values()]
        debug_info = f"æœªæ‰¾åˆ°é˜¶æ®µå†…å®¹: {stage_button_text}\n\n"
        debug_info += f"å¯ç”¨é˜¶æ®µ:\n" + "\n".join([f"- {stage}" for stage in available_stages])
        debug_info += f"\n\nå½“å‰é˜¶æ®µå†å²è®°å½•æ•°é‡: {len(self.stage_history)}"
        
        return debug_info
    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        try:
            config = self.service._config
            if not isinstance(config, dict):
                return ["é…ç½®æ ¼å¼é”™è¯¯"]
                
            llm_config = config.get("llm", {})
            if not isinstance(llm_config, dict):
                return ["LLMé…ç½®æ ¼å¼é”™è¯¯"]
                
            models = []
            for provider, provider_config in llm_config.items():
                if isinstance(provider_config, dict):
                    model_name = provider_config.get("model-name", provider)
                    enabled = provider_config.get("enabled", False)
                    status = "âœ…" if enabled else "âŒ"
                    models.append(f"{status} {provider}: {model_name}")
            return models
        except Exception as e:
            logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            return ["é…ç½®åŠ è½½å¤±è´¥"]
    
    def switch_model(self, provider: str) -> str:
        """åˆ‡æ¢æ¨¡å‹æä¾›å•†"""
        try:
            new_model = self.service.get_chatmodel_by_provider(provider)
            if new_model:
                self.llm_model = new_model
                # é‡æ–°åˆå§‹åŒ–å·¥ä½œæµæ„å»ºå™¨
                self.workflow_builder = DeepResearchWorkflow(self.service)
                
                try:
                    model_name = new_model.model_name()
                except:
                    model_name = str(new_model)
                
                logger.info(f"å·²åˆ‡æ¢åˆ°æ¨¡å‹: {provider} - {model_name}")
                return f"âœ… å·²åˆ‡æ¢åˆ°: {provider} - {model_name}"
            else:
                return f"âŒ æ— æ³•åˆ‡æ¢åˆ°æ¨¡å‹: {provider}"
        except Exception as e:
            logger.error(f"åˆ‡æ¢æ¨¡å‹å¤±è´¥: {e}")
            return f"âŒ åˆ‡æ¢å¤±è´¥: {str(e)}"
    
    def is_markdown_content(self, content: str) -> bool:
        """æ™ºèƒ½æ£€æµ‹å†…å®¹æ˜¯å¦åŒ…å«markdownæ ¼å¼"""
        if not content or len(content.strip()) < 10:
            return False
        
        # ä½¿ç”¨ç±»å¸¸é‡æ£€æµ‹markdownç‰¹å¾
        for pattern in self.MARKDOWN_PATTERNS:
            if re.search(pattern, content, re.MULTILINE):
                return True
        
        # æ£€æµ‹å¤šä¸ªæ¢è¡Œç¬¦ï¼ˆmarkdownæ–‡æ¡£ç‰¹å¾ï¼‰
        if content.count('\n\n') >= 2:
            return True
            
        return False
    
    def enhance_markdown_content(self, content: str) -> str:
        """å¢å¼ºmarkdownå†…å®¹çš„æ˜¾ç¤ºæ•ˆæœ"""
        if not content:
            return content
        
        # ä¸ºæ ‡é¢˜æ·»åŠ é€‚å½“çš„é—´è·
        content = re.sub(r'(?<!^)(\n)(#+\s)', r'\n\n\2', content, flags=re.MULTILINE)
        
        # ç¡®ä¿åˆ—è¡¨é¡¹æ ¼å¼æ­£ç¡®
        content = re.sub(r'(\n)([â€¢\-\*]\s)', r'\1\n\2', content)
        
        # ç¡®ä¿ç¼–å·åˆ—è¡¨æ ¼å¼æ­£ç¡®
        content = re.sub(r'(\n)(\d+\.\s)', r'\1\n\2', content)
        
        # ç¡®ä¿ä»£ç å—å‰åæœ‰ç©ºè¡Œ
        content = re.sub(r'(?<!^)(\n)(```)', r'\n\n\2', content)
        content = re.sub(r'(```.*?```\n)(?!\n)', r'\1\n', content, flags=re.DOTALL)
        
        return content.strip()
    
    def _format_stage_content(self, stage_info: Dict[str, str], include_metadata: bool = True) -> str:
        """æ ¼å¼åŒ–é˜¶æ®µå†…å®¹æ˜¾ç¤º"""
        content = stage_info['content']
        
        if include_metadata:
            formatted_content = f"## {stage_info['icon']} {stage_info['name']}\n\n"
            formatted_content += f"**ç ”ç©¶ä¸»é¢˜:** {self.current_research_topic}\n\n"
            formatted_content += f"**å®Œæˆæ—¶é—´:** {stage_info['timestamp']}\n\n"
            formatted_content += f"**å†…å®¹é•¿åº¦:** {len(content)} å­—ç¬¦\n\n"
            formatted_content += "---\n\n"
            formatted_content += content
            return formatted_content
        else:
            return content
    
    def _create_stage_buttons(self) -> List[str]:
        """åˆ›å»ºå·²å®Œæˆé˜¶æ®µçš„æŒ‰é’®åˆ—è¡¨"""
        buttons = []
        logger.debug(f"åˆ›å»ºé˜¶æ®µæŒ‰é’®ï¼Œå·²å®Œæˆé˜¶æ®µ: {self.completed_stages}")
        logger.debug(f"é˜¶æ®µå†å²è®°å½•: {list(self.stage_history.keys())}")
        
        for stage_id in self.STAGE_ORDER:
            if stage_id in self.completed_stages and stage_id in self.stage_history:
                stage_info = self.stage_history[stage_id]
                button_text = f"{stage_info['icon']} {stage_info['name']}"
                buttons.append(button_text)
                logger.debug(f"æ·»åŠ é˜¶æ®µæŒ‰é’®: {button_text}")
        
        return buttons
    
    def _should_update_stage_selector(self, previous_buttons: List[str], current_buttons: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°é˜¶æ®µé€‰æ‹©å™¨ï¼ˆåªæœ‰æ–°å¢é˜¶æ®µæ—¶æ‰æ›´æ–°ï¼‰"""
        return len(current_buttons) > len(previous_buttons)
    
    def _format_content_for_display(self, content: str, format_mode: str, is_final_report: bool = False) -> str:
        """æ ¼å¼åŒ–å†…å®¹ç”¨äºæ˜¾ç¤º"""
        if format_mode == "Markdownæ¸²æŸ“":
            if self.is_markdown_content(content):
                return self.enhance_markdown_content(content)
            elif is_final_report:
                return f"## ğŸ“„ ç ”ç©¶æŠ¥å‘Š\n\n```text\n{content}\n```"
            elif len(content) > self.LONG_TEXT_MIN_LENGTH:
                return f"```\n{content}\n```"
            else:
                return content
        else:
            return content
    
    def _create_gradio_update_tuple(self, status: str, content: str, progress: str, 
                                   stage_buttons: List[str], format_mode: str,
                                   is_final_report: bool = False) -> tuple:
        """åˆ›å»ºæ ‡å‡†çš„Gradioæ›´æ–°å…ƒç»„"""
        if is_final_report:
            formatted_content = self._format_content_for_display(content, format_mode, True)
            if format_mode == "Markdownæ¸²æŸ“":
                return (status, "âœ… ç ”ç©¶å®Œæˆ", progress, 
                       formatted_content, 
                       gr.update(value=content, visible=False),
                       gr.update(visible=True),
                       gr.update(visible=False),
                       gr.update(choices=stage_buttons))
            else:
                return (status, "âœ… ç ”ç©¶å®Œæˆ", progress, 
                       "è¯·åˆ‡æ¢åˆ°åŸå§‹æ–‡æœ¬æ¨¡å¼æŸ¥çœ‹å®Œæ•´å†…å®¹", 
                       gr.update(value=content, visible=True),
                       gr.update(visible=False),
                       gr.update(visible=True),
                       gr.update(choices=stage_buttons))
        else:
            stage_md_display = self._format_content_for_display(content, format_mode)
            return (status, stage_md_display, progress, 
                   gr.update(),  # research_report_md
                   gr.update(),  # research_report_text
                   gr.update(visible=True if format_mode == "Markdownæ¸²æŸ“" else False),
                   gr.update(value=content, visible=True if format_mode == "åŸå§‹æ–‡æœ¬" else False),
                   gr.update(choices=stage_buttons))


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆç”¨äºç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼‰"""
    parser = argparse.ArgumentParser(description="Deep Research Workflow Gradio App")
    parser.add_argument("--host", default="127.0.0.1", help="ä¸»æœºåœ°å€")
    parser.add_argument("--port", type=int, default=7861, help="ç«¯å£å·")
    parser.add_argument("--share", action="store_true", help="åˆ›å»ºå…¬å…±é“¾æ¥")
    parser.add_argument("--config", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dev", action="store_true", help="å¼€å‘æ¨¡å¼")
    return parser.parse_args()


def create_gradio_interface(app: DeepResearchApp):
    """åˆ›å»º Gradio ç•Œé¢"""
    
    with gr.Blocks(
        title="Deep Research - æ·±åº¦ç ”ç©¶å·¥ä½œæµ",
        theme=gr.themes.Soft(),
        css="""
        .research-container { 
            max-height: 600px; 
            overflow-y: auto; 
            scroll-behavior: smooth;
        }
        .status-info { 
            background-color: #f0f8ff; 
            padding: 10px; 
            border-radius: 5px; 
            margin: 5px 0; 
        }
        .progress-info {
            background-color: #f5f5f5;
            padding: 10px;
            border-radius: 5px;
            font-family: monospace;
            white-space: pre-wrap;
        }
        .report-container {
            max-height: 500px;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 15px;
            border-radius: 5px;
            background-color: #fafafa;
        }
        /* Markdownæ¸²æŸ“æ ·å¼ä¼˜åŒ– */
        .report-container h1, .report-container h2, .report-container h3 {
            color: #2563eb;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
        }
        .report-container h1 {
            border-bottom: 2px solid #e5e7eb;
            padding-bottom: 0.3em;
        }
        .report-container h2 {
            border-bottom: 1px solid #e5e7eb;
            padding-bottom: 0.2em;
        }
        .report-container ul, .report-container ol {
            padding-left: 1.5em;
            margin: 0.5em 0;
        }
        .report-container li {
            margin: 0.2em 0;
        }
        .report-container blockquote {
            border-left: 4px solid #e5e7eb;
            margin: 1em 0;
            padding-left: 1em;
            color: #6b7280;
        }
        .report-container code {
            background-color: #f3f4f6;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Monaco', 'Consolas', monospace;
        }
        .report-container pre {
            background-color: #1f2937;
            color: #f9fafb;
            padding: 1em;
            border-radius: 5px;
            overflow-x: auto;
        }
        .report-container table {
            border-collapse: collapse;
            width: 100%;
            margin: 1em 0;
        }
        .report-container th, .report-container td {
            border: 1px solid #e5e7eb;
            padding: 0.5em;
            text-align: left;
        }
        .report-container th {
            background-color: #f3f4f6;
            font-weight: bold;
        }
        /* é˜¶æ®µé€‰æ‹©å™¨æ ·å¼ */
        .stage-selector {
            background-color: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            padding: 8px;
        }
        .stage-selector label {
            font-weight: 600;
            color: #374151;
        }
        /* æ ‡ç­¾é¡µå†…å®¹æ ·å¼ä¼˜åŒ– */
        .gradio-tabs .gradio-tabitem {
            padding: 20px;
        }
        /* é˜¶æ®µè¯¦æƒ…æ˜¾ç¤ºæ ·å¼ */
        .stage-detail {
            background-color: #fefefe;
            border: 2px solid #e5e7eb;
            border-radius: 8px;
            max-height: 600px;
            overflow-y: auto;
        }
        /* æ ‡ç­¾é¡µä¸­çš„æŠ¥å‘Šå®¹å™¨æ ·å¼ */
        .gradio-tabs .report-container {
            max-height: 600px;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 20px;
            border-radius: 8px;
            background-color: #fafafa;
            margin-top: 10px;
        }
        """,
    ) as demo:
        
        gr.Markdown("""
        # ğŸ”¬ Deep Research - æ·±åº¦ç ”ç©¶å·¥ä½œæµ
        
        **ä¸“ä¸šçš„è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶åˆ†æå·¥å…·**
        
        æœ¬å·¥å…·é€šè¿‡å…­ä¸ªè¿ç»­çš„åˆ†æé˜¶æ®µï¼Œå¯¹å¤æ‚ä¸»é¢˜è¿›è¡Œå…¨é¢ã€æ·±å…¥çš„ç ”ç©¶å’Œåˆ†æï¼š
        1. ğŸ“Š **ä¸»é¢˜åˆ†æ** - åˆ†æç ”ç©¶ä¸»é¢˜çš„æ ¸å¿ƒå†…å®¹å’Œç ”ç©¶èŒƒå›´
        2. ğŸ“‹ **ç ”ç©¶è§„åˆ’** - åˆ¶å®šè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’å’Œåˆ†ææ¡†æ¶  
        3. ğŸ“š **ä¿¡æ¯æ”¶é›†** - ç³»ç»Ÿæ€§æ”¶é›†åŸºç¡€ä¿¡æ¯å’ŒèƒŒæ™¯èµ„æ–™
        4. ğŸ”¬ **æ·±åº¦åˆ†æ** - è¿›è¡Œè¶‹åŠ¿åˆ†æå’Œå…³è”åˆ†æ
        5. âœ… **äº¤å‰éªŒè¯** - éªŒè¯å…³é”®äº‹å®å’Œæ•°æ®å‡†ç¡®æ€§
        6. ğŸ“„ **æ€»ç»“æŠ¥å‘Š** - æ•´åˆæ‰€æœ‰ç ”ç©¶æˆæœç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        """)
        
        with gr.Row():
            with gr.Column(scale=2):
                # ä¸»è¦ç ”ç©¶ç•Œé¢
                gr.Markdown("## ğŸ¯ ç ”ç©¶é…ç½®")
                
                research_topic = gr.Textbox(
                    label="ç ”ç©¶ä¸»é¢˜",
                    placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦æ·±åº¦ç ”ç©¶çš„ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ä¸å‘å±•è¶‹åŠ¿",
                    lines=3,
                    max_lines=5
                )
                
                with gr.Row():
                    save_intermediate = gr.Checkbox(
                        label="ä¿å­˜ä¸­é—´æ–‡æ¡£",
                        value=True,
                        info="ä¿å­˜æ¯ä¸ªé˜¶æ®µçš„åˆ†æç»“æœ"
                    )
                    save_final_report = gr.Checkbox(
                        label="ä¿å­˜æœ€ç»ˆæŠ¥å‘Š",
                        value=True,
                        info="å°†æœ€ç»ˆæŠ¥å‘Šä¿å­˜ä¸ºæ–‡ä»¶"
                    )
                    enable_stream = gr.Checkbox(
                        label="æµå¼æ¨¡å¼",
                        value=True,
                        info="å®æ—¶æ˜¾ç¤ºåˆ†æè¿›åº¦"
                    )
                
                with gr.Row():
                    start_btn = gr.Button("ğŸš€ å¼€å§‹æ·±åº¦ç ”ç©¶", variant="primary", scale=2)
                    status_btn = gr.Button("ğŸ“Š æŸ¥çœ‹çŠ¶æ€", scale=1)
                
                # çŠ¶æ€æ˜¾ç¤º
                gr.Markdown("## ğŸ“ˆ æ‰§è¡ŒçŠ¶æ€")
                
                status_display = gr.Textbox(
                    label="å½“å‰çŠ¶æ€",
                    value="ç­‰å¾…å¼€å§‹ç ”ç©¶...",
                    interactive=False,
                    elem_classes="status-info"
                )
                
                # å½“å‰é˜¶æ®µæ˜¾ç¤ºï¼ˆæ”¯æŒmarkdownï¼‰
                current_stage_md = gr.Markdown(
                    value="**å½“å‰é˜¶æ®µ:** æœªå¼€å§‹",
                    visible=True
                )
                
                current_stage_text = gr.Textbox(
                    label="å½“å‰é˜¶æ®µ",
                    value="æœªå¼€å§‹",
                    interactive=False,
                    visible=False
                )
                
                progress_log = gr.Textbox(
                    label="è¿›åº¦æ—¥å¿—",
                    value="",
                    interactive=False,
                    lines=8,
                    elem_classes="progress-info"
                )
                
                # å·²å®Œæˆé˜¶æ®µå†å²æŸ¥çœ‹
                gr.Markdown("## ğŸ“‹ é˜¶æ®µå†å²")
                stage_selector = gr.Radio(
                    choices=[],
                    label="å·²å®Œæˆé˜¶æ®µ",
                    info="ç‚¹å‡»ç›´æ¥æŸ¥çœ‹é˜¶æ®µè¯¦ç»†å†…å®¹",
                    interactive=True,
                    elem_classes="stage-selector"
                )
            
            with gr.Column(scale=1):
                # æ˜¾ç¤ºæ ¼å¼æ§åˆ¶
                gr.Markdown("## ğŸ¨ æ˜¾ç¤ºè®¾ç½®")
                
                format_toggle = gr.Radio(
                    choices=["Markdownæ¸²æŸ“", "åŸå§‹æ–‡æœ¬"],
                    value="Markdownæ¸²æŸ“",
                    label="æŠ¥å‘Šæ˜¾ç¤ºæ ¼å¼",
                    info="é€‰æ‹©ç ”ç©¶æŠ¥å‘Šçš„æ˜¾ç¤ºæ ¼å¼"
                )
                
                # æ¨¡å‹é…ç½®å’Œç®¡ç†
                gr.Markdown("## âš™ï¸ æ¨¡å‹é…ç½®")
                
                # å®‰å…¨è·å–å½“å‰æ¨¡å‹åç§°
                try:
                    current_model_name = app.llm_model.model_name()
                except:
                    current_model_name = str(app.llm_model)
                
                model_info = gr.Markdown(f"**å½“å‰æ¨¡å‹:** {current_model_name}")
                
                model_list = gr.Dropdown(
                    label="å¯ç”¨æ¨¡å‹",
                    choices=app.get_available_models(),
                    interactive=False,
                    info="ç³»ç»Ÿä¸­é…ç½®çš„æ‰€æœ‰æ¨¡å‹"
                )
                
                provider_input = gr.Textbox(
                    placeholder="è¾“å…¥æä¾›å•†åç§°åˆ‡æ¢æ¨¡å‹",
                    label="åˆ‡æ¢æ¨¡å‹",
                    info="ä¾‹å¦‚: deepseek, openai, ollama"
                )
                
                switch_btn = gr.Button("åˆ‡æ¢æ¨¡å‹")
                
                switch_result = gr.Textbox(
                    label="åˆ‡æ¢ç»“æœ",
                    interactive=False,
                    lines=2
                )
                
        
        # å†…å®¹æ˜¾ç¤ºåŒºåŸŸ - ä½¿ç”¨æ ‡ç­¾é¡µç»„ç»‡
        with gr.Tabs():
            with gr.TabItem("ğŸ“„ ç ”ç©¶æŠ¥å‘Š"):
                # Markdownæ¸²æŸ“æ˜¾ç¤ºåŒºåŸŸ
                research_report_md = gr.Markdown(
                    value="ç ”ç©¶æŠ¥å‘Šå°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
                    elem_classes="report-container",
                    visible=True
                )
                
                # åŸå§‹æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸ  
                research_report_text = gr.Textbox(
                    label="æ·±åº¦ç ”ç©¶æŠ¥å‘Šï¼ˆåŸå§‹æ–‡æœ¬ï¼‰",
                    value="ç ”ç©¶æŠ¥å‘Šå°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
                    interactive=False,
                    lines=20,
                    elem_classes="report-container",
                    visible=False
                )
            
            with gr.TabItem("ğŸ” é˜¶æ®µè¯¦æƒ…"):
                stage_detail_display = gr.Markdown(
                    value="ç‚¹å‡»å·¦ä¾§é˜¶æ®µæŒ‰é’®æŸ¥çœ‹è¯¦ç»†å†…å®¹...",
                    elem_classes="report-container"
                )
        
        # ä½¿ç”¨ç¤ºä¾‹
        with gr.Accordion("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹", open=False):
            gr.Markdown("""
            ### ç ”ç©¶ä¸»é¢˜ç¤ºä¾‹ï¼š
            
            **ç§‘æŠ€ç±»ï¼š**
            - äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ä¸å‘å±•è¶‹åŠ¿
            - åŒºå—é“¾æŠ€æœ¯åœ¨é‡‘èç§‘æŠ€ä¸­çš„åˆ›æ–°åº”ç”¨
            - é‡å­è®¡ç®—æŠ€æœ¯çš„å‘å±•ç°çŠ¶ä¸æœªæ¥å±•æœ›
            - å¯æŒç»­èƒ½æºæŠ€æœ¯çš„å‘å±•è¶‹åŠ¿
            
            **å•†ä¸šç±»ï¼š**
            - æ–°é›¶å”®æ¨¡å¼çš„å‘å±•è¶‹åŠ¿ä¸æŒ‘æˆ˜
            - è¿œç¨‹åŠå…¬å¯¹ä¼ä¸šç®¡ç†æ¨¡å¼çš„å½±å“
            - æ•°å­—åŒ–è½¬å‹åœ¨ä¼ ç»Ÿåˆ¶é€ ä¸šçš„åº”ç”¨
            
            **ç¤¾ä¼šç±»ï¼š**
            - è€é¾„åŒ–ç¤¾ä¼šçš„æŒ‘æˆ˜ä¸åº”å¯¹ç­–ç•¥
            - æ•°å­—é¸¿æ²Ÿå¯¹ç¤¾ä¼šå…¬å¹³çš„å½±å“
            - åœ¨çº¿æ•™è‚²çš„å‘å±•è¶‹åŠ¿ä¸è´¨é‡ä¿éšœ
            
            ### ä½¿ç”¨å»ºè®®ï¼š
            1. ğŸ“ **æ˜ç¡®ä¸»é¢˜**ï¼šé€‰æ‹©å…·ä½“ã€æœ‰é’ˆå¯¹æ€§çš„ç ”ç©¶ä¸»é¢˜
            2. âš™ï¸ **é€‰æ‹©æ¨¡å¼**ï¼šå»ºè®®å¼€å¯æµå¼æ¨¡å¼æŸ¥çœ‹å®æ—¶è¿›åº¦
            3. ğŸ’¾ **ä¿å­˜è®¾ç½®**ï¼šå»ºè®®ä¿å­˜ä¸­é—´æ–‡æ¡£å’Œæœ€ç»ˆæŠ¥å‘Š
            4. ğŸ¨ **æ˜¾ç¤ºæ ¼å¼**ï¼šæ™ºèƒ½è¯†åˆ«Markdownæ ¼å¼ï¼Œè‡ªåŠ¨æ¸²æŸ“æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰
            5. â° **è€å¿ƒç­‰å¾…**ï¼šæ·±åº¦ç ”ç©¶éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
            
            ### ğŸ’¡ Markdownæ”¯æŒç‰¹æ€§ï¼š
            - âœ… **è‡ªåŠ¨æ£€æµ‹**ï¼šæ™ºèƒ½è¯†åˆ«å†…å®¹ä¸­çš„Markdownæ ¼å¼
            - âœ… **æ ·å¼æ¸²æŸ“**ï¼šæ”¯æŒæ ‡é¢˜ã€ç²—ä½“ã€æ–œä½“ã€åˆ—è¡¨ã€ä»£ç å—ç­‰
            - âœ… **è¡¨æ ¼æ”¯æŒ**ï¼šè‡ªåŠ¨æ¸²æŸ“è¡¨æ ¼æ ¼å¼
            - âœ… **ä»£ç é«˜äº®**ï¼šä»£ç å—è‡ªåŠ¨è¯­æ³•é«˜äº®
            - âœ… **åŒæ¨¡å¼**ï¼šå¯åœ¨Markdownæ¸²æŸ“å’ŒåŸå§‹æ–‡æœ¬é—´åˆ‡æ¢
            """)
        
        # äº‹ä»¶ç»‘å®š
        def handle_start_research(topic, save_inter, save_final, stream_mode, format_mode):
            """å¤„ç†å¼€å§‹ç ”ç©¶äº‹ä»¶"""
            for result in app.start_research(topic, save_inter, save_final, stream_mode):
                if len(result) == 5:
                    status, stage_or_report, progress, stage_buttons, _ = result
                    if "å®Œæˆ!" in status and len(stage_or_report) > 100:  # è¿™æ˜¯æœ€ç»ˆæŠ¥å‘Š
                        # æ ¹æ®æ ¼å¼æ¨¡å¼å†³å®šæ˜¾ç¤ºæ–¹å¼
                        if format_mode == "Markdownæ¸²æŸ“":
                            # æ™ºèƒ½æ£€æµ‹å’Œå¢å¼ºmarkdown
                            if app.is_markdown_content(stage_or_report):
                                enhanced_content = app.enhance_markdown_content(stage_or_report)
                                yield (status, "âœ… ç ”ç©¶å®Œæˆ", progress, 
                                      enhanced_content, 
                                      gr.update(value=stage_or_report, visible=False),
                                      gr.update(visible=True),
                                      gr.update(visible=False),
                                      gr.update(choices=stage_buttons))
                            else:
                                # ä¸æ˜¯markdownï¼Œæ˜¾ç¤ºä¸ºæ™®é€šæ–‡æœ¬ä½†ç”¨markdownç»„ä»¶æ˜¾ç¤º
                                formatted_content = f"## ğŸ“„ ç ”ç©¶æŠ¥å‘Š\n\n```text\n{stage_or_report}\n```"
                                yield (status, "âœ… ç ”ç©¶å®Œæˆ", progress, 
                                      formatted_content, 
                                      gr.update(value=stage_or_report, visible=False),
                                      gr.update(visible=True),
                                      gr.update(visible=False),
                                      gr.update(choices=stage_buttons))
                        else:
                            # åŸå§‹æ–‡æœ¬æ¨¡å¼
                            yield (status, "âœ… ç ”ç©¶å®Œæˆ", progress, 
                                  "è¯·åˆ‡æ¢åˆ°åŸå§‹æ–‡æœ¬æ¨¡å¼æŸ¥çœ‹å®Œæ•´å†…å®¹", 
                                  gr.update(value=stage_or_report, visible=True),
                                  gr.update(visible=False),
                                  gr.update(visible=True),
                                  gr.update(choices=stage_buttons))
                    else:  # è¿™æ˜¯è¿›åº¦æ›´æ–°æˆ–ä¸­é—´é˜¶æ®µå†…å®¹
                        # æ™ºèƒ½å¤„ç†å½“å‰é˜¶æ®µçš„å†…å®¹æ˜¾ç¤º
                        stage_display = stage_or_report
                        stage_md_display = stage_or_report
                        
                        if format_mode == "Markdownæ¸²æŸ“" and stage_or_report:
                            # å¦‚æœæ˜¯markdownæ ¼å¼æ¨¡å¼ï¼Œæ£€æµ‹å†…å®¹æ ¼å¼
                            if app.is_markdown_content(stage_or_report):
                                stage_md_display = app.enhance_markdown_content(stage_or_report)
                            elif len(stage_or_report) > 100:
                                # é•¿æ–‡æœ¬ç”¨ä»£ç å—åŒ…è£…
                                stage_md_display = f"```\n{stage_or_report}\n```"
                            else:
                                # çŸ­æ–‡æœ¬ç›´æ¥æ˜¾ç¤º
                                stage_md_display = stage_or_report
                        
                        # è¿”å›8ä¸ªå€¼æ¥åŒ¹é…æ‰€æœ‰outputs
                        yield (status, stage_md_display, progress, 
                              gr.update(),  # research_report_md
                              gr.update(),  # research_report_text
                              gr.update(visible=True if format_mode == "Markdownæ¸²æŸ“" else False),  # current_stage_md
                              gr.update(value=stage_display, visible=True if format_mode == "åŸå§‹æ–‡æœ¬" else False),  # current_stage_text
                              gr.update(choices=stage_buttons))  # stage_selector - ä¸é‡ç½®ç”¨æˆ·é€‰æ‹©
                else:
                    # é”™è¯¯æƒ…å†µï¼Œè¿”å›8ä¸ªå€¼
                    yield (result[0], "", "", 
                          gr.update(), gr.update(), 
                          gr.update(), gr.update(), gr.update())
        
        def handle_status_check():
            """å¤„ç†çŠ¶æ€æŸ¥è¯¢äº‹ä»¶"""
            return app.get_workflow_status()
        
        def handle_model_switch(provider):
            """å¤„ç†æ¨¡å‹åˆ‡æ¢äº‹ä»¶"""
            if not provider.strip():
                return "âŒ è¯·è¾“å…¥æä¾›å•†åç§°", model_info.value
            
            result = app.switch_model(provider)
            
            # æ›´æ–°æ¨¡å‹ä¿¡æ¯
            try:
                new_model_name = app.llm_model.model_name()
            except:
                new_model_name = str(app.llm_model)
            
            new_model_info = f"**å½“å‰æ¨¡å‹:** {new_model_name}"
            return result, new_model_info
        
        def handle_format_toggle(format_mode, current_md_content, current_text_content):
            """å¤„ç†æ ¼å¼åˆ‡æ¢äº‹ä»¶"""
            if format_mode == "Markdownæ¸²æŸ“":
                return (gr.update(visible=True), gr.update(visible=False),
                       gr.update(visible=True), gr.update(visible=False))
            else:
                return (gr.update(visible=False), gr.update(visible=True),
                       gr.update(visible=False), gr.update(visible=True))
        
        def handle_stage_selection(stage_selection):
            """å¤„ç†é˜¶æ®µé€‰æ‹©äº‹ä»¶ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹"""
            logger.info(f"é˜¶æ®µé€‰æ‹©äº‹ä»¶è§¦å‘ï¼Œé€‰æ‹©: {stage_selection}, å·¥ä½œæµè¿è¡ŒçŠ¶æ€: {app.workflow_running}")
            
            if not stage_selection:
                return "ç‚¹å‡»å·¦ä¾§é˜¶æ®µæŒ‰é’®æŸ¥çœ‹è¯¦ç»†å†…å®¹..."
            
            # æ— è®ºå·¥ä½œæµæ˜¯å¦è¿è¡Œï¼Œéƒ½å…è®¸æŸ¥çœ‹å·²å®Œæˆçš„é˜¶æ®µå†…å®¹
            content = app.get_stage_content(stage_selection)
            logger.info(f"è·å–åˆ°é˜¶æ®µå†…å®¹ï¼Œé•¿åº¦: {len(content)}")
            
            # å¦‚æœå·¥ä½œæµæ­£åœ¨è¿è¡Œï¼Œåœ¨å†…å®¹é¡¶éƒ¨æ·»åŠ æç¤ºä¿¡æ¯
            if app.workflow_running:
                status_note = "## ğŸ” æŸ¥çœ‹å·²å®Œæˆé˜¶æ®µå†…å®¹\n\n> â³ **æç¤º:** å·¥ä½œæµæ­£åœ¨è¿è¡Œä¸­ï¼Œä»¥ä¸‹æ˜¯å·²å®Œæˆé˜¶æ®µçš„å†…å®¹\n\n---\n\n"
                content = status_note + content
            
            return content
        
        # ç»‘å®šäº‹ä»¶
        start_btn.click(
            handle_start_research,
            inputs=[research_topic, save_intermediate, save_final_report, enable_stream, format_toggle],
            outputs=[status_display, current_stage_md, progress_log, research_report_md, research_report_text, current_stage_md, current_stage_text, stage_selector],
            show_progress="minimal"
        )
        
        status_btn.click(
            handle_status_check,
            outputs=[status_display]
        )
        
        switch_btn.click(
            handle_model_switch,
            inputs=[provider_input],
            outputs=[switch_result, model_info]
        )
        
        # æ ¼å¼åˆ‡æ¢äº‹ä»¶
        format_toggle.change(
            handle_format_toggle,
            inputs=[format_toggle, research_report_md, research_report_text],
            outputs=[research_report_md, research_report_text, current_stage_md, current_stage_text]
        )
        
        # é˜¶æ®µé€‰æ‹©äº‹ä»¶ - ç›´æ¥è§¦å‘å†…å®¹æ˜¾ç¤º
        stage_selector.change(
            handle_stage_selection,
            inputs=[stage_selector],
            outputs=[stage_detail_display]
        )
    
    return demo


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    try:
        # åˆå§‹åŒ–åº”ç”¨
        logger.info("æ­£åœ¨åˆå§‹åŒ– Deep Research åº”ç”¨...")
        app = DeepResearchApp(args.config)
        
        # åˆ›å»º Gradio ç•Œé¢
        demo = create_gradio_interface(app)
        
        # å¯åŠ¨åº”ç”¨
        logger.info(f"å¯åŠ¨ Deep Research åº”ç”¨åœ¨ {args.host}:{args.port}")
        demo.launch(
            server_name=args.host,
            server_port=args.port,
            share=args.share,
            show_error=True
        )
        
    except Exception as e:
        logger.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        print("\nè¯·æ£€æŸ¥:")
        print("1. é…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¡® (vertex_flow/config/llm.yml)")
        print("2. æ˜¯å¦æœ‰å¯ç”¨çš„ LLM æä¾›å•†")
        print("3. API å¯†é’¥æ˜¯å¦é…ç½®æ­£ç¡®")
        return 1


if __name__ == "__main__":
    exit(main()) 