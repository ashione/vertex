#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Web Searchå·¥å…·ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨åŸºäºåšæŸ¥AIçš„Webæœç´¢å·¥å…·è¿›è¡Œå„ç§æœç´¢ä»»åŠ¡ã€‚
"""

import json

from vertex_flow.workflow.tools.web_search import create_web_search_tool, web_search_function


def example_basic_search():
    """åŸºç¡€æœç´¢ç¤ºä¾‹"""
    print("=== åŸºç¡€æœç´¢ç¤ºä¾‹ ===")

    # ç›´æ¥ä½¿ç”¨å‡½æ•°
    inputs = {"query": "äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•è¶‹åŠ¿ 2024", "count": 5, "summary": True}

    result = web_search_function(inputs)

    if result["success"]:
        print(f"æœç´¢æŸ¥è¯¢: {result['query']}")
        print(f"æ€»ç»“æœæ•°: {result['total_count']}")
        print(f"\nAIæ€»ç»“:\n{result['summary']}")
        print("\næœç´¢ç»“æœ:")
        for i, item in enumerate(result["results"], 1):
            print(f"{i}. {item['title']}")
            print(f"   URL: {item['url']}")
            print(f"   æ‘˜è¦: {item['snippet'][:100]}...")
            print()
    else:
        print(f"æœç´¢å¤±è´¥: {result['error']}")


def example_news_search():
    """æ–°é—»æœç´¢ç¤ºä¾‹"""
    print("=== æ–°é—»æœç´¢ç¤ºä¾‹ ===")

    inputs = {"query": "OpenAI GPT-4 æœ€æ–°æ¶ˆæ¯", "count": 3, "freshness": "noLimit", "summary": True}  # æœç´¢ä¸€å‘¨å†…çš„æ–°é—»

    result = web_search_function(inputs)

    if result["success"]:
        print(f"æœç´¢æŸ¥è¯¢: {result['query']}")
        print(f"\nä¸€å‘¨å†…ç›¸å…³æ–°é—»æ€»ç»“:\n{result['summary']}")
        print("\næœ€æ–°æ–°é—»:")
        for item in result["results"]:
            print(f"â€¢ {item['title']} ({item['site_name']})")
            print(f"  {item['url']}")
    else:
        print(f"æœç´¢å¤±è´¥: {result['error']}")


def example_academic_search():
    """å­¦æœ¯æœç´¢ç¤ºä¾‹"""
    print("=== å­¦æœ¯æœç´¢ç¤ºä¾‹ ===")

    inputs = {
        "query": "transformer architecture deep learning research papers",
        "count": 8,
        "freshness": "noLimit",
        "summary": True,
    }

    result = web_search_function(inputs)

    if result["success"]:
        print(f"æœç´¢æŸ¥è¯¢: {result['query']}")
        print(f"\nå­¦æœ¯èµ„æ–™æ€»ç»“:\n{result['summary']}")
        print("\nç›¸å…³å­¦æœ¯èµ„æº:")
        for item in result["results"]:
            if any(keyword in item["url"].lower() for keyword in ["arxiv", "scholar", "ieee", "acm"]):
                print(f"ğŸ“š {item['title']}")
                print(f"   {item['url']}")
                print(f"   {item['snippet'][:150]}...")
                print()
    else:
        print(f"æœç´¢å¤±è´¥: {result['error']}")


def example_function_tool_usage():
    """ä½œä¸ºFunctionToolä½¿ç”¨çš„ç¤ºä¾‹"""
    print("=== FunctionToolä½¿ç”¨ç¤ºä¾‹ ===")

    # åˆ›å»ºå·¥å…·å®ä¾‹
    search_tool = create_web_search_tool()

    print(f"å·¥å…·åç§°: {search_tool.name}")
    print(f"å·¥å…·æè¿°: {search_tool.description}")
    print(f"å·¥å…·ID: {search_tool.id}")
    print(f"\nå·¥å…·Schema:")
    print(json.dumps(search_tool.schema, indent=2, ensure_ascii=False))

    # ä½¿ç”¨å·¥å…·æ‰§è¡Œæœç´¢
    inputs = {"query": "Pythonæœºå™¨å­¦ä¹ åº“æ¨è", "count": 4, "summary": True}

    result = search_tool.execute(inputs)

    if result["success"]:
        print(f"\næœç´¢æˆåŠŸ!")
        print(f"æŸ¥è¯¢: {result['query']}")
        print(f"AIæ€»ç»“: {result['summary'][:200]}...")
        print(f"æ‰¾åˆ° {len(result['results'])} ä¸ªç»“æœ")
    else:
        print(f"\næœç´¢å¤±è´¥: {result['error']}")


def example_error_handling():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    print("=== é”™è¯¯å¤„ç†ç¤ºä¾‹ ===")

    # æµ‹è¯•ç©ºæŸ¥è¯¢
    result1 = web_search_function({"query": ""})
    print(f"ç©ºæŸ¥è¯¢ç»“æœ: {result1['error']}")

    # æµ‹è¯•æ— æ•ˆå‚æ•°
    result2 = web_search_function({"query": "æµ‹è¯•æŸ¥è¯¢", "count": -1, "freshness": "invalid"})  # æ— æ•ˆæ•°é‡  # æ— æ•ˆæ—¶æ•ˆæ€§
    print(f"æ— æ•ˆå‚æ•°å¤„ç†: æœç´¢ä»ç„¶æ‰§è¡Œï¼Œå‚æ•°è¢«è‡ªåŠ¨ä¿®æ­£")

    # æµ‹è¯•ç¼ºå°‘æŸ¥è¯¢å‚æ•°
    result3 = web_search_function({"count": 5})
    print(f"ç¼ºå°‘æŸ¥è¯¢å‚æ•°: {result3['error']}")


def example_integration_with_llm():
    """ä¸LLMé›†æˆä½¿ç”¨ç¤ºä¾‹"""
    print("=== LLMé›†æˆä½¿ç”¨ç¤ºä¾‹ ===")

    # æ¨¡æ‹ŸLLMè°ƒç”¨å·¥å…·çš„åœºæ™¯
    search_tool = create_web_search_tool()

    # å‡è®¾LLMå†³å®šéœ€è¦æœç´¢ä¿¡æ¯
    user_question = "è¯·å‘Šè¯‰æˆ‘å…³äºé‡å­è®¡ç®—çš„æœ€æ–°è¿›å±•"

    # LLMç”Ÿæˆçš„å·¥å…·è°ƒç”¨å‚æ•°
    tool_call_params = {
        "query": "é‡å­è®¡ç®—æœ€æ–°è¿›å±• 2025 çªç ´æ€§ç ”ç©¶",
        "count": 6,
        "freshness": "noLimit",
        "summary": True,
    }

    print(f"ç”¨æˆ·é—®é¢˜: {user_question}")
    print(f"LLMç”Ÿæˆçš„æœç´¢å‚æ•°: {tool_call_params}")

    # æ‰§è¡Œæœç´¢
    search_result = search_tool.execute(tool_call_params)

    if search_result["success"]:
        print(f"\næœç´¢æˆåŠŸï¼Œè·å¾—ä¿¡æ¯:")
        print(f"AIæ€»ç»“: {search_result['summary'][:300]}...")
        print(f"\nåŸºäºæœç´¢ç»“æœï¼ŒLLMå¯ä»¥ç”Ÿæˆæ›´å‡†ç¡®å’ŒåŠæ—¶çš„å›ç­”ã€‚")

        # æ¨¡æ‹ŸLLMä½¿ç”¨æœç´¢ç»“æœç”Ÿæˆå›ç­”
        print(f"\n[æ¨¡æ‹ŸLLMå›ç­”]")
        print(f"æ ¹æ®æœ€æ–°çš„æœç´¢ç»“æœï¼Œé‡å­è®¡ç®—é¢†åŸŸç¡®å®æœ‰ä»¥ä¸‹é‡è¦è¿›å±•...")
        print(f"(è¿™é‡ŒLLMä¼šåŸºäºsearch_result['summary']å’Œsearch_result['results']ç”Ÿæˆè¯¦ç»†å›ç­”)")
    else:
        print(f"æœç´¢å¤±è´¥: {search_result['error']}")
        print(f"LLMå°†åŸºäºå·²æœ‰çŸ¥è¯†å›ç­”ï¼Œä½†å¯èƒ½ä¸å¤ŸåŠæ—¶ã€‚")


if __name__ == "__main__":
    print("Web Searchå·¥å…·ä½¿ç”¨ç¤ºä¾‹\n")
    print("æ³¨æ„: è¿è¡Œè¿™äº›ç¤ºä¾‹éœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­æ­£ç¡®é…ç½®åšæŸ¥APIå¯†é’¥")
    print("é…ç½®è·¯å¾„: config/llm.yml ä¸­çš„ web-search.bocha.sk\n")

    try:
        example_basic_search()
        print("\n" + "=" * 50 + "\n")

        example_news_search()
        print("\n" + "=" * 50 + "\n")

        example_academic_search()
        print("\n" + "=" * 50 + "\n")

        example_function_tool_usage()
        print("\n" + "=" * 50 + "\n")

        example_error_handling()
        print("\n" + "=" * 50 + "\n")

        example_integration_with_llm()

    except Exception as e:
        print(f"ç¤ºä¾‹æ‰§è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶å’Œç½‘ç»œè¿æ¥")
