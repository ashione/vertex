#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦ç ”ç©¶å·¥ä½œæµé›†æˆç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨é›†æˆäº† WhileVertexGroup çš„æ–°å‹æ·±åº¦ç ”ç©¶å·¥ä½œæµ
è¿›è¡Œæ™ºèƒ½è¿­ä»£åˆ†æï¼Œå‚è€ƒäº† Dify å’Œ OpenAI çš„æ·±åº¦ç ”ç©¶æœ€ä½³å®è·µã€‚
"""

import asyncio
import json
import os
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from vertex_flow.workflow.service import VertexFlowService
from vertex_flow.workflow.app.deep_research_workflow import DeepResearchWorkflow
from vertex_flow.utils.logger import setup_logger

logger = setup_logger(__name__)


async def test_deep_research_integration():
    """æµ‹è¯•æ·±åº¦ç ”ç©¶å·¥ä½œæµé›†æˆ"""
    
    try:
        # åˆå§‹åŒ–æœåŠ¡
        logger.info("åˆå§‹åŒ– VertexFlow æœåŠ¡...")
        service = VertexFlowService()
        
        # è·å–æ¨¡å‹
        model = service.get_chatmodel()
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model}")
        
        # åˆ›å»ºæ·±åº¦ç ”ç©¶å·¥ä½œæµæ„å»ºå™¨
        workflow_builder = DeepResearchWorkflow(service, model, language="zh")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_topics = [
            "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨ç°çŠ¶ä¸å‘å±•è¶‹åŠ¿",
            "åŒºå—é“¾æŠ€æœ¯åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„åˆ›æ–°åº”ç”¨",
            "å¯æŒç»­èƒ½æºæŠ€æœ¯çš„å‘å±•å‰æ™¯ä¸æŒ‘æˆ˜"
        ]
        
        # é€‰æ‹©ä¸€ä¸ªæµ‹è¯•ä¸»é¢˜
        research_topic = test_topics[0]
        
        # é…ç½®è¾“å…¥æ•°æ®
        input_data = {
            "content": research_topic,
            "stream": False,  # ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼è¿›è¡Œæµ‹è¯•
            "save_intermediate": True,
            "save_final_report": True,
            "language": "zh",
            "env_vars": {},
            "user_vars": {},
        }
        
        logger.info(f"å¼€å§‹æ·±åº¦ç ”ç©¶æµ‹è¯•ï¼Œä¸»é¢˜: {research_topic}")
        
        # åˆ›å»ºå·¥ä½œæµ
        workflow = workflow_builder.create_workflow(input_data)
        
        # éªŒè¯å·¥ä½œæµç»“æ„
        logger.info("éªŒè¯å·¥ä½œæµç»“æ„...")
        vertices = list(workflow.vertices.values())
        edges = workflow.edges
        
        logger.info(f"å·¥ä½œæµåŒ…å« {len(vertices)} ä¸ªé¡¶ç‚¹:")
        for vertex in vertices:
            logger.info(f"  - {vertex.id}: {type(vertex).__name__}")
        
        logger.info(f"å·¥ä½œæµåŒ…å« {len(edges)} æ¡è¾¹")
        
        # æŸ¥æ‰¾ WhileVertexGroup
        while_vertex_group = None
        for vertex in vertices:
            if vertex.id == "while_analysis_steps_group":
                while_vertex_group = vertex
                break
        
        if while_vertex_group:
            logger.info("âœ… æ‰¾åˆ° WhileVertexGroup è¿­ä»£åˆ†æç»„")
            logger.info(f"  - å­å›¾é¡¶ç‚¹æ•°: {len(while_vertex_group.subgraph_vertices)}")
            logger.info(f"  - å­å›¾è¾¹æ•°: {len(while_vertex_group.subgraph_edges)}")
            
            # æ˜¾ç¤ºå­å›¾ç»“æ„
            for sub_vertex in while_vertex_group.subgraph_vertices:
                logger.info(f"    * å­é¡¶ç‚¹: {sub_vertex.id} ({type(sub_vertex).__name__})")
        else:
            logger.warning("âŒ æœªæ‰¾åˆ° WhileVertexGroup")
        
        # æ‰§è¡Œå·¥ä½œæµï¼ˆç®€åŒ–æµ‹è¯•ï¼‰
        logger.info("å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        
        # å‡†å¤‡è¾“å…¥
        workflow_input = {"content": research_topic}
        
        # æ‰§è¡Œå·¥ä½œæµ
        workflow.execute_workflow(workflow_input)
        result = workflow.result()
        
        logger.info("âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        
        # åˆ†æç»“æœ
        if result:
            logger.info("åˆ†ææ‰§è¡Œç»“æœ:")
            
            # æ£€æŸ¥å„é˜¶æ®µçš„è¾“å‡º
            stages_to_check = [
                "topic_analysis",
                "analysis_plan", 
                "extract_steps",
                "while_analysis_steps_group",
                "information_collection",
                "deep_analysis",
                "cross_validation",
                "summary_report"
            ]
            
            for stage in stages_to_check:
                if stage in result:
                    stage_result = result[stage]
                    if isinstance(stage_result, str):
                        content_preview = stage_result[:100] + "..." if len(stage_result) > 100 else stage_result
                    else:
                        content_preview = str(stage_result)[:100] + "..."
                    
                    logger.info(f"  {stage}: {content_preview}")
                else:
                    logger.info(f"  {stage}: æœªæ‰§è¡Œæˆ–æ— è¾“å‡º")
            
            # ç‰¹åˆ«å…³æ³¨è¿­ä»£åˆ†æç»“æœ
            if "while_analysis_steps_group" in result:
                while_result = result["while_analysis_steps_group"]
                logger.info("ğŸ”„ è¿­ä»£åˆ†æè¯¦ç»†ç»“æœ:")
                
                if isinstance(while_result, dict):
                    iteration_count = while_result.get('iteration_count', 0)
                    results = while_result.get('results', [])
                    logger.info(f"  - æ€»è¿­ä»£æ¬¡æ•°: {iteration_count}")
                    logger.info(f"  - åˆ†ææ­¥éª¤æ•°: {len(results)}")
                    
                    # æ˜¾ç¤ºå‰å‡ ä¸ªæ­¥éª¤çš„æ‘˜è¦
                    for i, step_result in enumerate(results[:3], 1):
                        if isinstance(step_result, dict):
                            step_info = step_result.get('step_info', {})
                            step_name = step_info.get('step_name', f'æ­¥éª¤{i}')
                            logger.info(f"    æ­¥éª¤ {i}: {step_name}")
                else:
                    logger.info(f"  - ç»“æœç±»å‹: {type(while_result)}")
                    logger.info(f"  - ç»“æœé¢„è§ˆ: {str(while_result)[:200]}...")
        
        return True
        
    except Exception as e:
        logger.error(f"æ·±åº¦ç ”ç©¶å·¥ä½œæµé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_workflow_structure():
    """æµ‹è¯•å·¥ä½œæµç»“æ„ï¼ˆä¸æ‰§è¡Œï¼‰"""
    
    try:
        logger.info("æµ‹è¯•å·¥ä½œæµç»“æ„...")
        
        # åˆå§‹åŒ–æœåŠ¡
        service = VertexFlowService()
        model = service.get_chatmodel()
        
        # åˆ›å»ºå·¥ä½œæµæ„å»ºå™¨
        workflow_builder = DeepResearchWorkflow(service, model, language="en")
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        input_data = {
            "content": "Test topic",
            "stream": False,
            "save_intermediate": False,
            "save_final_report": False,
            "language": "en",
            "env_vars": {},
            "user_vars": {},
        }
        
        # åˆ›å»ºå·¥ä½œæµ
        workflow = workflow_builder.create_workflow(input_data)
        
        # åˆ†æå·¥ä½œæµç»“æ„
        vertices = list(workflow.vertices.values())
        edges = workflow.edges
        
        logger.info("ğŸ“Š å·¥ä½œæµç»“æ„åˆ†æ:")
        logger.info(f"  - æ€»é¡¶ç‚¹æ•°: {len(vertices)}")
        logger.info(f"  - æ€»è¾¹æ•°: {len(edges)}")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡é¡¶ç‚¹
        vertex_types = {}
        for vertex in vertices:
            vertex_type = type(vertex).__name__
            vertex_types[vertex_type] = vertex_types.get(vertex_type, 0) + 1
        
        logger.info("  - é¡¶ç‚¹ç±»å‹ç»Ÿè®¡:")
        for vertex_type, count in vertex_types.items():
            logger.info(f"    * {vertex_type}: {count}")
        
        # æ£€æŸ¥å…³é”®é¡¶ç‚¹
        key_vertices = ["topic_analysis", "analysis_plan", "extract_steps", "while_analysis_steps_group"]
        logger.info("  - å…³é”®é¡¶ç‚¹æ£€æŸ¥:")
        
        for key_vertex in key_vertices:
            found = any(v.id == key_vertex for v in vertices)
            status = "âœ…" if found else "âŒ"
            logger.info(f"    {status} {key_vertex}")
        
        # æ£€æŸ¥ WhileVertexGroup çš„å­å›¾ç»“æ„
        while_vertex = next((v for v in vertices if v.id == "while_analysis_steps_group"), None)
        if while_vertex and hasattr(while_vertex, 'subgraph_vertices'):
            logger.info("  - WhileVertexGroup å­å›¾ç»“æ„:")
            logger.info(f"    * å­é¡¶ç‚¹æ•°: {len(while_vertex.subgraph_vertices)}")
            logger.info(f"    * å­è¾¹æ•°: {len(while_vertex.subgraph_edges)}")
            
            for sub_vertex in while_vertex.subgraph_vertices:
                logger.info(f"      - {sub_vertex.id}: {type(sub_vertex).__name__}")
        
        logger.info("âœ… å·¥ä½œæµç»“æ„æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"å·¥ä½œæµç»“æ„æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ æ·±åº¦ç ”ç©¶å·¥ä½œæµé›†æˆæµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•å·¥ä½œæµç»“æ„
    print("\n1. æµ‹è¯•å·¥ä½œæµç»“æ„...")
    structure_ok = test_workflow_structure()
    
    if structure_ok:
        print("âœ… å·¥ä½œæµç»“æ„æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ å·¥ä½œæµç»“æ„æµ‹è¯•å¤±è´¥")
        return
    
    # è¯¢é—®æ˜¯å¦æ‰§è¡Œå®Œæ•´æµ‹è¯•
    print("\n2. æ˜¯å¦æ‰§è¡Œå®Œæ•´çš„æ·±åº¦ç ”ç©¶æµ‹è¯•ï¼Ÿ")
    print("   æ³¨æ„ï¼šå®Œæ•´æµ‹è¯•å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´å’ŒAPIè°ƒç”¨")
    
    user_input = input("   è¾“å…¥ 'y' æˆ– 'yes' ç»§ç»­ï¼Œå…¶ä»–é”®è·³è¿‡: ").lower().strip()
    
    if user_input in ['y', 'yes']:
        print("\nå¼€å§‹å®Œæ•´çš„æ·±åº¦ç ”ç©¶æµ‹è¯•...")
        
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        import asyncio
        success = asyncio.run(test_deep_research_integration())
        
        if success:
            print("âœ… æ·±åº¦ç ”ç©¶å·¥ä½œæµé›†æˆæµ‹è¯•å®Œæˆ")
        else:
            print("âŒ æ·±åº¦ç ”ç©¶å·¥ä½œæµé›†æˆæµ‹è¯•å¤±è´¥")
    else:
        print("è·³è¿‡å®Œæ•´æµ‹è¯•")
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main() 